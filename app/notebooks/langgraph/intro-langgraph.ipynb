{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T15:59:24.567185Z",
     "start_time": "2025-10-09T15:59:24.564891Z"
    }
   },
   "cell_type": "code",
   "source": "# %pip install openai>1.50.0 langchain>0.3.0 langgraph langchainhub langchain-openai langchain-community langchain-cli langchain_ollama tavily-python>=0.5.0 langchain_nomic nomic[local] langserve faiss-cpu tiktoken pypdf chroma jira google-search-results numexpr beautifulsoup4 scikit-learn",
   "id": "7ab066668bc186ac",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T15:59:24.618661Z",
     "start_time": "2025-10-09T15:59:24.615270Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langgraph.graph import START,  END, MessagesState\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langgraph.graph import StateGraph"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T15:59:24.651091Z",
     "start_time": "2025-10-09T15:59:24.648551Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# %pip install upgrade pip\n",
    "# %pip install grandalf\n",
    "# %pip install -U langgraph\n",
    "# !pip install -U  langchain_core"
   ],
   "id": "3f21fed8eb0b31db",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T15:59:24.680509Z",
     "start_time": "2025-10-09T15:59:24.677438Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def node1(state:MessagesState , config:RunnableConfig):\n",
    "    return {\"messages\": f\"Hello, {state['messages']}!\"}\n",
    "\n",
    "def node2(state:MessagesState):\n",
    "    return {\"messages\": f\"Would you like to know more?\"}\n",
    "    "
   ],
   "id": "32cbb8193001cca3",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T15:59:24.694228Z",
     "start_time": "2025-10-09T15:59:24.691741Z"
    }
   },
   "cell_type": "code",
   "source": "builder = StateGraph(MessagesState)",
   "id": "5ddf7710760b4486",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T15:59:24.708235Z",
     "start_time": "2025-10-09T15:59:24.704758Z"
    }
   },
   "cell_type": "code",
   "source": [
    "builder.add_node(node1)\n",
    "builder.add_node(node2)\n",
    "#everythin starts with START node\n",
    "builder.add_edge(START,\"node1\")\n",
    "builder.add_edge(\"node1\",\"node2\")\n",
    "builder.add_edge(\"node2\",END)\n",
    "\n",
    "graph = builder.compile()\n"
   ],
   "id": "9bd4c0aa856c3e9c",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T15:59:24.721916Z",
     "start_time": "2025-10-09T15:59:24.717506Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from IPython.display import display,Image\n",
    "# Image(graph.get_graph().draw_mermaid_png())\n",
    "print(graph.get_graph().draw_ascii())"
   ],
   "id": "e80016d6015bdc61",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+  \r\n",
      "| __start__ |  \r\n",
      "+-----------+  \r\n",
      "      *        \r\n",
      "      *        \r\n",
      "      *        \r\n",
      "  +-------+    \r\n",
      "  | node1 |    \r\n",
      "  +-------+    \r\n",
      "      *        \r\n",
      "      *        \r\n",
      "      *        \r\n",
      "  +-------+    \r\n",
      "  | node2 |    \r\n",
      "  +-------+    \r\n",
      "      *        \r\n",
      "      *        \r\n",
      "      *        \r\n",
      " +---------+   \r\n",
      " | __end__ |   \r\n",
      " +---------+   \n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T15:59:24.731997Z",
     "start_time": "2025-10-09T15:59:24.724442Z"
    }
   },
   "cell_type": "code",
   "source": "graph.invoke({\"messages\" : [{\"role\": \"user\", \"content\": \" gyan\"}]})",
   "id": "6744b9d73755df8e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content=' gyan', additional_kwargs={}, response_metadata={}, id='1f29b6d5-83c9-4c73-a928-f0fd41a1fdc0'),\n",
       "  HumanMessage(content=\"Hello, [HumanMessage(content=' gyan', additional_kwargs={}, response_metadata={}, id='1f29b6d5-83c9-4c73-a928-f0fd41a1fdc0')]!\", additional_kwargs={}, response_metadata={}, id='fdaf764b-3e4a-451f-a2ae-edccad7bde73'),\n",
       "  HumanMessage(content='Would you like to know more?', additional_kwargs={}, response_metadata={}, id='57cd36bf-56e7-4aa0-8686-240e393e5593')]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T15:59:24.766312Z",
     "start_time": "2025-10-09T15:59:24.760214Z"
    }
   },
   "cell_type": "code",
   "source": "#Edges  ",
   "id": "26206867e89c330d",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T15:59:24.794773Z",
     "start_time": "2025-10-09T15:59:24.792184Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def node1(state:dict):\n",
    "    print(\"in node1\")\n",
    "    return state\n",
    "\n",
    "def node2(state:dict):\n",
    "    print(\"in node2\")\n",
    "    return state\n",
    "\n"
   ],
   "id": "7401318962e10f47",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T15:59:25.552184Z",
     "start_time": "2025-10-09T15:59:24.822198Z"
    }
   },
   "cell_type": "code",
   "source": [
    "builder=StateGraph(dict)\n",
    "builder.add_node(node1)\n",
    "builder.add_node(node2)\n",
    "\n",
    "builder.add_edge(START, \"node1\")\n",
    "builder.add_edge(\"node1\",\"node2\")\n",
    "builder.add_edge(\"node2\",END)\n",
    "builder.compile()"
   ],
   "id": "58a6b46a44b88b0",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to reach https://mermaid.ink API while trying to render your graph. Status code: 204.\n\nTo resolve this issue:\n1. Check your internet connection and try again\n2. Try with higher retry settings: `draw_mermaid_png(..., max_retries=5, retry_delay=2.0)`\n3. Use the Pyppeteer rendering method which will render your graph locally in a browser: `draw_mermaid_png(..., draw_method=MermaidDrawMethod.PYPPETEER)`",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\IPython\\core\\formatters.py:1036\u001B[39m, in \u001B[36mMimeBundleFormatter.__call__\u001B[39m\u001B[34m(self, obj, include, exclude)\u001B[39m\n\u001B[32m   1033\u001B[39m     method = get_real_method(obj, \u001B[38;5;28mself\u001B[39m.print_method)\n\u001B[32m   1035\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m method \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1036\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmethod\u001B[49m\u001B[43m(\u001B[49m\u001B[43minclude\u001B[49m\u001B[43m=\u001B[49m\u001B[43minclude\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexclude\u001B[49m\u001B[43m=\u001B[49m\u001B[43mexclude\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1037\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1038\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langgraph\\pregel\\main.py:769\u001B[39m, in \u001B[36mPregel._repr_mimebundle_\u001B[39m\u001B[34m(self, **kwargs)\u001B[39m\n\u001B[32m    765\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_repr_mimebundle_\u001B[39m(\u001B[38;5;28mself\u001B[39m, **kwargs: Any) -> \u001B[38;5;28mdict\u001B[39m[\u001B[38;5;28mstr\u001B[39m, Any]:\n\u001B[32m    766\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Mime bundle used by Jupyter to display the graph\"\"\"\u001B[39;00m\n\u001B[32m    767\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m {\n\u001B[32m    768\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mtext/plain\u001B[39m\u001B[33m\"\u001B[39m: \u001B[38;5;28mrepr\u001B[39m(\u001B[38;5;28mself\u001B[39m),\n\u001B[32m--> \u001B[39m\u001B[32m769\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mimage/png\u001B[39m\u001B[33m\"\u001B[39m: \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mget_graph\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdraw_mermaid_png\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m,\n\u001B[32m    770\u001B[39m     }\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain_core\\runnables\\graph.py:704\u001B[39m, in \u001B[36mGraph.draw_mermaid_png\u001B[39m\u001B[34m(self, curve_style, node_colors, wrap_label_n_words, output_file_path, draw_method, background_color, padding, max_retries, retry_delay, frontmatter_config, base_url)\u001B[39m\n\u001B[32m    694\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mlangchain_core\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mrunnables\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mgraph_mermaid\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (  \u001B[38;5;66;03m# noqa: PLC0415\u001B[39;00m\n\u001B[32m    695\u001B[39m     draw_mermaid_png,\n\u001B[32m    696\u001B[39m )\n\u001B[32m    698\u001B[39m mermaid_syntax = \u001B[38;5;28mself\u001B[39m.draw_mermaid(\n\u001B[32m    699\u001B[39m     curve_style=curve_style,\n\u001B[32m    700\u001B[39m     node_colors=node_colors,\n\u001B[32m    701\u001B[39m     wrap_label_n_words=wrap_label_n_words,\n\u001B[32m    702\u001B[39m     frontmatter_config=frontmatter_config,\n\u001B[32m    703\u001B[39m )\n\u001B[32m--> \u001B[39m\u001B[32m704\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mdraw_mermaid_png\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    705\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmermaid_syntax\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmermaid_syntax\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    706\u001B[39m \u001B[43m    \u001B[49m\u001B[43moutput_file_path\u001B[49m\u001B[43m=\u001B[49m\u001B[43moutput_file_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    707\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdraw_method\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdraw_method\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    708\u001B[39m \u001B[43m    \u001B[49m\u001B[43mbackground_color\u001B[49m\u001B[43m=\u001B[49m\u001B[43mbackground_color\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    709\u001B[39m \u001B[43m    \u001B[49m\u001B[43mpadding\u001B[49m\u001B[43m=\u001B[49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    710\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmax_retries\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmax_retries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    711\u001B[39m \u001B[43m    \u001B[49m\u001B[43mretry_delay\u001B[49m\u001B[43m=\u001B[49m\u001B[43mretry_delay\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    712\u001B[39m \u001B[43m    \u001B[49m\u001B[43mbase_url\u001B[49m\u001B[43m=\u001B[49m\u001B[43mbase_url\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    713\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain_core\\runnables\\graph_mermaid.py:322\u001B[39m, in \u001B[36mdraw_mermaid_png\u001B[39m\u001B[34m(mermaid_syntax, output_file_path, draw_method, background_color, padding, max_retries, retry_delay, base_url)\u001B[39m\n\u001B[32m    316\u001B[39m     img_bytes = asyncio.run(\n\u001B[32m    317\u001B[39m         _render_mermaid_using_pyppeteer(\n\u001B[32m    318\u001B[39m             mermaid_syntax, output_file_path, background_color, padding\n\u001B[32m    319\u001B[39m         )\n\u001B[32m    320\u001B[39m     )\n\u001B[32m    321\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m draw_method == MermaidDrawMethod.API:\n\u001B[32m--> \u001B[39m\u001B[32m322\u001B[39m     img_bytes = \u001B[43m_render_mermaid_using_api\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    323\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmermaid_syntax\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    324\u001B[39m \u001B[43m        \u001B[49m\u001B[43moutput_file_path\u001B[49m\u001B[43m=\u001B[49m\u001B[43moutput_file_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    325\u001B[39m \u001B[43m        \u001B[49m\u001B[43mbackground_color\u001B[49m\u001B[43m=\u001B[49m\u001B[43mbackground_color\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    326\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmax_retries\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmax_retries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    327\u001B[39m \u001B[43m        \u001B[49m\u001B[43mretry_delay\u001B[49m\u001B[43m=\u001B[49m\u001B[43mretry_delay\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    328\u001B[39m \u001B[43m        \u001B[49m\u001B[43mbase_url\u001B[49m\u001B[43m=\u001B[49m\u001B[43mbase_url\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    329\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    330\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    331\u001B[39m     supported_methods = \u001B[33m\"\u001B[39m\u001B[33m, \u001B[39m\u001B[33m\"\u001B[39m.join([m.value \u001B[38;5;28;01mfor\u001B[39;00m m \u001B[38;5;129;01min\u001B[39;00m MermaidDrawMethod])\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain_core\\runnables\\graph_mermaid.py:480\u001B[39m, in \u001B[36m_render_mermaid_using_api\u001B[39m\u001B[34m(mermaid_syntax, output_file_path, background_color, file_type, max_retries, retry_delay, base_url)\u001B[39m\n\u001B[32m    475\u001B[39m     \u001B[38;5;66;03m# For other status codes, fail immediately\u001B[39;00m\n\u001B[32m    476\u001B[39m     msg = (\n\u001B[32m    477\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mFailed to reach \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mbase_url\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m API while trying to render \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    478\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33myour graph. Status code: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresponse.status_code\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m    479\u001B[39m     ) + error_msg_suffix\n\u001B[32m--> \u001B[39m\u001B[32m480\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(msg)\n\u001B[32m    482\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m (requests.RequestException, requests.Timeout) \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    483\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m attempt < max_retries:\n\u001B[32m    484\u001B[39m         \u001B[38;5;66;03m# Exponential backoff with jitter\u001B[39;00m\n",
      "\u001B[31mValueError\u001B[39m: Failed to reach https://mermaid.ink API while trying to render your graph. Status code: 204.\n\nTo resolve this issue:\n1. Check your internet connection and try again\n2. Try with higher retry settings: `draw_mermaid_png(..., max_retries=5, retry_delay=2.0)`\n3. Use the Pyppeteer rendering method which will render your graph locally in a browser: `draw_mermaid_png(..., draw_method=MermaidDrawMethod.PYPPETEER)`"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph at 0x2861e8e9f20>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T15:59:25.557377Z",
     "start_time": "2025-10-09T15:59:25.553526Z"
    }
   },
   "cell_type": "code",
   "source": "print(graph.get_graph().print_ascii())",
   "id": "848c41836885ef0f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+  \r\n",
      "| __start__ |  \r\n",
      "+-----------+  \r\n",
      "      *        \r\n",
      "      *        \r\n",
      "      *        \r\n",
      "  +-------+    \r\n",
      "  | node1 |    \r\n",
      "  +-------+    \r\n",
      "      *        \r\n",
      "      *        \r\n",
      "      *        \r\n",
      "  +-------+    \r\n",
      "  | node2 |    \r\n",
      "  +-------+    \r\n",
      "      *        \r\n",
      "      *        \r\n",
      "      *        \r\n",
      " +---------+   \r\n",
      " | __end__ |   \r\n",
      " +---------+   \n",
      "None\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T15:59:25.560913Z",
     "start_time": "2025-10-09T15:59:25.558543Z"
    }
   },
   "cell_type": "code",
   "source": "#Conditional Edge   ",
   "id": "4db013497bf51896",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T18:02:39.519791Z",
     "start_time": "2025-10-09T18:02:38.801360Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langgraph.graph import START, END, MessagesState, StateGraph\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from typing import Literal\n",
    "import random"
   ],
   "id": "ba8d61026877bfb4",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T15:59:25.573679Z",
     "start_time": "2025-10-09T15:59:25.563627Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "# Define the node functions\n",
    "def node1(state: MessagesState):\n",
    "    print(\"in node1\")\n",
    "    return state\n",
    "\n",
    "def node2(state: MessagesState):\n",
    "    print(\"in node2\")\n",
    "    return state\n",
    "\n",
    "def router_function(state: MessagesState) -> Literal[\"node3\", \"node4\"]:\n",
    "    return random.choice([\"node3\", \"node4\"])\n",
    "\n",
    "def node3(state: MessagesState):\n",
    "    print(\"in node3\")\n",
    "    return state\n",
    "\n",
    "def node4(state: MessagesState):\n",
    "    print(\"in node4\")\n",
    "    return state\n",
    "\n",
    "# Create the state graph\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "# Add nodes\n",
    "builder.add_node(\"node1\", node1)\n",
    "builder.add_node(\"node2\", node2)\n",
    "builder.add_node(\"node3\", node3)\n",
    "builder.add_node(\"node4\", node4)\n",
    "\n",
    "# Define the edges\n",
    "builder.add_edge(START, \"node1\")\n",
    "builder.add_edge(\"node1\", \"node2\")\n",
    "builder.add_conditional_edges(\n",
    "    \"node2\",\n",
    "    router_function,\n",
    "    {\n",
    "        \"node3\": \"node3\",\n",
    "        \"node4\": \"node4\"\n",
    "    }\n",
    ")\n",
    "builder.add_edge(\"node3\", \"node4\")\n",
    "builder.add_edge(\"node4\", END)\n",
    "\n",
    "# Compile the graph\n",
    "graph = builder.compile()\n",
    "\n",
    "# Optional: Visualize the graph\n",
    "print(graph.get_graph().draw_ascii())\n",
    "# \n",
    "# Run the graph\n",
    "initial_state = MessagesState(messages=[])\n",
    "final_state = graph.invoke(initial_state, config=RunnableConfig())\n"
   ],
   "id": "134f59d186fcdb4b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       +-----------+    \r\n",
      "       | __start__ |    \r\n",
      "       +-----------+    \r\n",
      "              *         \r\n",
      "              *         \r\n",
      "              *         \r\n",
      "         +-------+      \r\n",
      "         | node1 |      \r\n",
      "         +-------+      \r\n",
      "              *         \r\n",
      "              *         \r\n",
      "              *         \r\n",
      "         +-------+      \r\n",
      "         | node2 |      \r\n",
      "         +-------+      \r\n",
      "         .        .     \r\n",
      "       ..          .    \r\n",
      "      .             ..  \r\n",
      "+-------+             . \r\n",
      "| node3 |           ..  \r\n",
      "+-------+          .    \r\n",
      "         *        .     \r\n",
      "          **    ..      \r\n",
      "            *  .        \r\n",
      "         +-------+      \r\n",
      "         | node4 |      \r\n",
      "         +-------+      \r\n",
      "              *         \r\n",
      "              *         \r\n",
      "              *         \r\n",
      "        +---------+     \r\n",
      "        | __end__ |     \r\n",
      "        +---------+     \n",
      "in node1\n",
      "in node2\n",
      "in node4\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#State",
   "id": "4537a6712b1f9de8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T18:02:44.667955Z",
     "start_time": "2025-10-09T18:02:44.665547Z"
    }
   },
   "cell_type": "code",
   "source": "from pydantic import BaseModel, Field\n",
   "id": "9cd8250ba07f6557",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T16:00:45.437899Z",
     "start_time": "2025-10-09T16:00:45.432869Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class GraphState(BaseModel):\n",
    "    number :int\n",
    "    result:int"
   ],
   "id": "fe1199e502c6bd3e",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T16:00:55.645005Z",
     "start_time": "2025-10-09T16:00:55.640841Z"
    }
   },
   "cell_type": "code",
   "source": "builder = StateGraph(GraphState)",
   "id": "e124a11c2e84c02d",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T16:02:15.221858Z",
     "start_time": "2025-10-09T16:02:15.218033Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def node_double(state:GraphState):\n",
    "    print(\"Current State \\n\\n\")\n",
    "    print(f\"{state.number=}, {state=}\")\n",
    "    return {\"result\": 2 * state.number}\n",
    "    "
   ],
   "id": "4d0f280b55e87964",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T16:04:16.901350Z",
     "start_time": "2025-10-09T16:04:16.897625Z"
    }
   },
   "cell_type": "code",
   "source": [
    "builder.add_node(node_double)\n",
    "builder.add_edge(START,\"node_double\")\n",
    "builder.add_edge(\"node_double\",END)\n",
    "graph = builder.compile()"
   ],
   "id": "9345ff0bb4e762c3",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T16:04:23.368461Z",
     "start_time": "2025-10-09T16:04:23.361467Z"
    }
   },
   "cell_type": "code",
   "source": "print(graph.get_graph().draw_ascii())",
   "id": "3e18c1f084c04c3d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " +-----------+   \r\n",
      " | __start__ |   \r\n",
      " +-----------+   \r\n",
      "        *        \r\n",
      "        *        \r\n",
      "        *        \r\n",
      "+-------------+  \r\n",
      "| node_double |  \r\n",
      "+-------------+  \r\n",
      "        *        \r\n",
      "        *        \r\n",
      "        *        \r\n",
      "  +---------+    \r\n",
      "  | __end__ |    \r\n",
      "  +---------+    \n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T16:04:52.767181Z",
     "start_time": "2025-10-09T16:04:52.758203Z"
    }
   },
   "cell_type": "code",
   "source": "graph.invoke({\"number\": 100, \"result\":89})",
   "id": "533b09c88065adb8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current State \n",
      "\n",
      "\n",
      "state.number=100, state=GraphState(number=100, result=89)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'number': 100, 'result': 200}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now with these concepts, let us first setup a useful graph",
   "id": "13b47fb6e003c5a0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T18:01:53.694634Z",
     "start_time": "2025-10-09T18:01:53.676785Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "def _set_env_from_file(var: str, file_path: str = \"openai_key.txt\"):\n",
    "    \"\"\"\n",
    "    Reads an API key from a specified file and sets it as an environment variable.\n",
    "    \"\"\"\n",
    "    if not os.environ.get(var):\n",
    "        try:\n",
    "            # The 'with open' statement ensures the file is closed automatically\n",
    "            with open(file_path, 'r') as f:\n",
    "                # Read the first line and strip any leading/trailing whitespace\n",
    "                key = f.readline().strip()\n",
    "\n",
    "            if key:\n",
    "                os.environ[var] = key\n",
    "                print(f\"Successfully loaded {var} from {file_path}\")\n",
    "            else:\n",
    "                print(f\"Warning: {file_path} is empty.\")\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: Key file not found at {file_path}. Please create the file.\")\n",
    "\n",
    "# --- Execution ---\n",
    "# Set the environment variable OPENAI_API_KEY from the file\n",
    "_set_env_from_file('OPENAI_API_KEY',file_path=\"../../keys/openai\")\n"
   ],
   "id": "1952a79611a4b733",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded OPENAI_API_KEY from ../../keys/openai\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T18:07:43.647146Z",
     "start_time": "2025-10-09T18:07:43.643632Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from openai import OpenAI\n",
    "# %pip install openai"
   ],
   "id": "df0a1ae8b8ece935",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T18:07:44.657561Z",
     "start_time": "2025-10-09T18:07:44.360845Z"
    }
   },
   "cell_type": "code",
   "source": "client=OpenAI()",
   "id": "1afc6bc81b39fab",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T18:02:00.414647Z",
     "start_time": "2025-10-09T18:02:00.411178Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def call_openai_api(promt:str):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": promt}],      \n",
    "    )\n",
    "    return response.choices[0].message.content"
   ],
   "id": "83f86cada6c78c9e",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T18:08:04.998648Z",
     "start_time": "2025-10-09T18:08:01.134046Z"
    }
   },
   "cell_type": "code",
   "source": "output = call_openai_api(\"Suggest which is better to start as a beginner, langchain or langgraph in less than 4 sentences\")",
   "id": "65f40e096fabfadb",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T18:08:06.753145Z",
     "start_time": "2025-10-09T18:08:06.747197Z"
    }
   },
   "cell_type": "code",
   "source": "output",
   "id": "d52f3ed200274e3a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"For beginners, LangChain might be a better choice as it offers a more comprehensive set of tools and documentation for building applications with language models. Its robust community and resources can help speed up the learning process. LangGraph, while more specialized, may require a deeper understanding of graph-based structures. Ultimately, if you're looking for broader versatility and support, start with LangChain.\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T18:08:48.002552Z",
     "start_time": "2025-10-09T18:08:47.996381Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def llm_suggest_concept(state: MessagesState):\n",
    "    prompt = \"Suggest a concept based on this theme given: \"\n",
    "    theme = state['messages'][-1].content\n",
    "    print(f\"{prompt=}, {theme=}\")\n",
    "    output_story = call_openai_api(prompt+theme)\n",
    "    return {\"messages\" : f\"The output concept from llm : {output_story}\"} \n",
    "\n",
    "def editor_node(state:MessagesState):\n",
    "    prompt= \"Edit the story and simplify it to 3 paragraphs\"\n",
    "    story=state['messages'][-1].content\n",
    "    print(f\"{prompt=}, {story=}\")\n",
    "    edited_story = call_openai_api(prompt+story)\n",
    "    return {\"messages\" : f\"The edited story: {edited_story}\"}\n",
    "\n",
    "graph_builder = StateGraph(MessagesState)\n",
    "graph_builder.add_node(llm_suggest_concept)\n",
    "graph_builder.add_node(editor_node)\n",
    "\n",
    "graph_builder.add_edge(START, \"llm_suggest_concept\")\n",
    "graph_builder.add_edge(\"llm_suggest_concept\", \"editor_node\")\n",
    "graph_builder.add_edge(\"editor_node\",END)\n",
    "\n",
    "output_graph =graph_builder.compile()\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ],
   "id": "63292151f163d42b",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T18:08:49.981930Z",
     "start_time": "2025-10-09T18:08:49.975008Z"
    }
   },
   "cell_type": "code",
   "source": "output_graph.get_graph().print_ascii()",
   "id": "a4d93fbaf3124cde",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     +-----------+       \r\n",
      "     | __start__ |       \r\n",
      "     +-----------+       \r\n",
      "            *            \r\n",
      "            *            \r\n",
      "            *            \r\n",
      "+---------------------+  \r\n",
      "| llm_suggest_concept |  \r\n",
      "+---------------------+  \r\n",
      "            *            \r\n",
      "            *            \r\n",
      "            *            \r\n",
      "    +-------------+      \r\n",
      "    | editor_node |      \r\n",
      "    +-------------+      \r\n",
      "            *            \r\n",
      "            *            \r\n",
      "            *            \r\n",
      "      +---------+        \r\n",
      "      | __end__ |        \r\n",
      "      +---------+        \n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T18:09:11.949838Z",
     "start_time": "2025-10-09T18:08:51.334165Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "output = output_graph.invoke({\"messages\": [{\"role\":\"user\", \"content\": \"Langraph or Langchain\"}]})\n"
   ],
   "id": "116851ac0396f09f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt='Suggest a concept based on this theme given: ', theme='Langraph or Langchain'\n",
      "prompt='Edit the story and simplify it to 3 paragraphs', story='The output concept from llm : Certainly! Here’s a concept based on the theme of \"Langraph\" or \"Langchain\" that could be applied in the field of natural language processing, specifically for language understanding and generation:\\n\\n### Concept: **LangChain - A Multi-Modal Language Processing Framework**\\n\\n#### Overview:\\nLangChain is a robust, multi-modal framework designed to enhance the processing and understanding of different languages through a combination of natural language processing (NLP) and knowledge graph technologies. Its primary focus is to enable richer and more context-aware language interactions in applications such as chatbots, voice assistants, translation services, and content generation tools.\\n\\n#### Components:\\n\\n1. **Language Modules**:\\n   - **Language Comprehension**: Tools that utilize advanced NLP techniques to comprehend and analyze input text from users in various languages.\\n   - **Language Generation**: Capabilities that enable the framework to generate coherent, contextually-relevant text across multiple languages, focusing on fluency and cultural nuances.\\n\\n2. **Knowledge Graph Integration**:\\n   - Leverage knowledge graphs to provide contextual understanding and enrich conversations. LangChain can connect words and phrases to broader concepts and entities, enabling deeper language comprehension.\\n   - The framework can dynamically pull in real-world knowledge, supporting answers that are not only grammatically correct but contextually relevant.\\n\\n3. **Chain of Thought Mechanism**:\\n   - A unique mechanism that simulates human-like reasoning in language processing. When generating responses, LangChain can outline a chain of thought, displaying logical progression in its responses, which helps in understanding complex queries.\\n\\n4. **User Personalization**:\\n   - Implement machine learning algorithms to learn user preferences over time, customizing the interaction experience. LangChain can adjust tone, formality, and content based on user interaction history.\\n\\n5. **Multi-Modal Capabilities**:\\n   - Support for incorporating visual and auditory inputs. For example, users can upload images or voice recordings, and the framework processes these inputs to provide text-based responses or insights.\\n\\n6. **Collaborative Learning**:\\n   - Leverage user interactions to continuously improve the model. As users engage with the system, it learns from real conversations, gradually enhancing its understanding of language nuances and context.\\n\\n7. **API & Integration**:\\n   - Offer a robust API for developers to integrate LangChain into various platforms, enabling them to build applications that require advanced language processing capabilities without developing the underlying infrastructure from scratch.\\n\\n#### Use Cases:\\n- **Customer Support**: Automated chatbots that provide responsive and intelligent support by understanding user queries and retrieving relevant knowledge.\\n- **Language Translation**: A translation service that not only converts text but also captures the intent, tone, and cultural context of conversations.\\n- **Content Creation**: Tools for marketers and writers that help generate engaging content while considering SEO strategies and audience targeting.\\n- **E-Learning**: Language tutors that utilize real-time feedback and contextual learning to enhance the language-learning experience.\\n\\n### Conclusion:\\nLangChain represents a fusion of language processing and knowledge representation, creating richer, more interactive language experiences. By empowering applications with a deeper understanding of language and context, LangChain aims to change how humans and machines communicate, bridging gaps across cultures and technologies.'\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T18:09:13.854225Z",
     "start_time": "2025-10-09T18:09:13.849986Z"
    }
   },
   "cell_type": "code",
   "source": "Markdown(output[\"messages\"][-1].content)",
   "id": "e440f73f2be9a7d8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "The edited story: ### Concept: **LangChain - A Multi-Modal Language Processing Framework**\n\nLangChain is an advanced framework that enhances language processing by combining natural language processing (NLP) and knowledge graph technologies. It aims to improve interactions in applications like chatbots, voice assistants, translation services, and content generation tools by enabling deeper comprehension and context-aware dialogues across multiple languages.\n\nThe framework features several key components, including language modules for comprehension and generation, which ensure accurate and culturally relevant text. It integrates knowledge graphs that provide contextual insights, allowing LangChain to connect words to broader concepts. Additionally, the unique chain of thought mechanism simulates human reasoning, creating logical responses that help tackle complex queries. User personalization and multi-modal capabilities enable customized experiences and the processing of diverse inputs, such as images and voice recordings.\n\nLangChain can be applied in various scenarios, including customer support through intelligent chatbots, translation services that convey intent and tone, content creation tools for marketers, and interactive language tutors for e-learning. By merging language understanding with contextual knowledge, LangChain transforms human-machine communication and enhances interactions across cultures and technologies."
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T18:09:28.120713Z",
     "start_time": "2025-10-09T18:09:28.115743Z"
    }
   },
   "cell_type": "code",
   "source": "output",
   "id": "ca19e80649290f01",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Langraph or Langchain', additional_kwargs={}, response_metadata={}, id='fe42f32c-f890-408d-82e8-3c290561903e'),\n",
       "  HumanMessage(content='The output concept from llm : Certainly! Here’s a concept based on the theme of \"Langraph\" or \"Langchain\" that could be applied in the field of natural language processing, specifically for language understanding and generation:\\n\\n### Concept: **LangChain - A Multi-Modal Language Processing Framework**\\n\\n#### Overview:\\nLangChain is a robust, multi-modal framework designed to enhance the processing and understanding of different languages through a combination of natural language processing (NLP) and knowledge graph technologies. Its primary focus is to enable richer and more context-aware language interactions in applications such as chatbots, voice assistants, translation services, and content generation tools.\\n\\n#### Components:\\n\\n1. **Language Modules**:\\n   - **Language Comprehension**: Tools that utilize advanced NLP techniques to comprehend and analyze input text from users in various languages.\\n   - **Language Generation**: Capabilities that enable the framework to generate coherent, contextually-relevant text across multiple languages, focusing on fluency and cultural nuances.\\n\\n2. **Knowledge Graph Integration**:\\n   - Leverage knowledge graphs to provide contextual understanding and enrich conversations. LangChain can connect words and phrases to broader concepts and entities, enabling deeper language comprehension.\\n   - The framework can dynamically pull in real-world knowledge, supporting answers that are not only grammatically correct but contextually relevant.\\n\\n3. **Chain of Thought Mechanism**:\\n   - A unique mechanism that simulates human-like reasoning in language processing. When generating responses, LangChain can outline a chain of thought, displaying logical progression in its responses, which helps in understanding complex queries.\\n\\n4. **User Personalization**:\\n   - Implement machine learning algorithms to learn user preferences over time, customizing the interaction experience. LangChain can adjust tone, formality, and content based on user interaction history.\\n\\n5. **Multi-Modal Capabilities**:\\n   - Support for incorporating visual and auditory inputs. For example, users can upload images or voice recordings, and the framework processes these inputs to provide text-based responses or insights.\\n\\n6. **Collaborative Learning**:\\n   - Leverage user interactions to continuously improve the model. As users engage with the system, it learns from real conversations, gradually enhancing its understanding of language nuances and context.\\n\\n7. **API & Integration**:\\n   - Offer a robust API for developers to integrate LangChain into various platforms, enabling them to build applications that require advanced language processing capabilities without developing the underlying infrastructure from scratch.\\n\\n#### Use Cases:\\n- **Customer Support**: Automated chatbots that provide responsive and intelligent support by understanding user queries and retrieving relevant knowledge.\\n- **Language Translation**: A translation service that not only converts text but also captures the intent, tone, and cultural context of conversations.\\n- **Content Creation**: Tools for marketers and writers that help generate engaging content while considering SEO strategies and audience targeting.\\n- **E-Learning**: Language tutors that utilize real-time feedback and contextual learning to enhance the language-learning experience.\\n\\n### Conclusion:\\nLangChain represents a fusion of language processing and knowledge representation, creating richer, more interactive language experiences. By empowering applications with a deeper understanding of language and context, LangChain aims to change how humans and machines communicate, bridging gaps across cultures and technologies.', additional_kwargs={}, response_metadata={}, id='d304d088-bbc9-42dd-84e8-ff33edb14c83'),\n",
       "  HumanMessage(content='The edited story: ### Concept: **LangChain - A Multi-Modal Language Processing Framework**\\n\\nLangChain is an advanced framework that enhances language processing by combining natural language processing (NLP) and knowledge graph technologies. It aims to improve interactions in applications like chatbots, voice assistants, translation services, and content generation tools by enabling deeper comprehension and context-aware dialogues across multiple languages.\\n\\nThe framework features several key components, including language modules for comprehension and generation, which ensure accurate and culturally relevant text. It integrates knowledge graphs that provide contextual insights, allowing LangChain to connect words to broader concepts. Additionally, the unique chain of thought mechanism simulates human reasoning, creating logical responses that help tackle complex queries. User personalization and multi-modal capabilities enable customized experiences and the processing of diverse inputs, such as images and voice recordings.\\n\\nLangChain can be applied in various scenarios, including customer support through intelligent chatbots, translation services that convey intent and tone, content creation tools for marketers, and interactive language tutors for e-learning. By merging language understanding with contextual knowledge, LangChain transforms human-machine communication and enhances interactions across cultures and technologies.', additional_kwargs={}, response_metadata={}, id='6245f62d-d696-4ca7-923c-ab4492961209')]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T15:59:25.663116Z",
     "start_time": "2025-10-09T15:59:25.659038Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "af15f35c4191fa3d",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T15:59:25.666987Z",
     "start_time": "2025-10-09T15:59:25.665114Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "c3c7fec9e5eae34e",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T15:59:25.671550Z",
     "start_time": "2025-10-09T15:59:25.668294Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "132e635052e32f03",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T15:59:25.676075Z",
     "start_time": "2025-10-09T15:59:25.673275Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "fbedea44586ccb7c",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T15:59:25.682075Z",
     "start_time": "2025-10-09T15:59:25.680232Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "ae8ba48539b2a91f",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T15:59:25.685166Z",
     "start_time": "2025-10-09T15:59:25.683387Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "1505055547fce441",
   "outputs": [],
   "execution_count": 27
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
