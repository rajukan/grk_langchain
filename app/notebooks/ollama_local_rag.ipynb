{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "# # Langchain package\n",
    "# %pip install -qU langchain\n",
    "# \n",
    "# # Local vector store via Chroma\n",
    "# %pip install -qU langchain_chroma\n",
    "# \n",
    "# # Local inference and embeddings via Ollama\n",
    "# %pip install -qU langchain_ollama\n",
    "# \n",
    "# # Web Loader\n",
    "# %pip install -qU beautifulsoup4"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T00:53:23.736970Z",
     "start_time": "2025-10-05T00:53:23.727025Z"
    }
   },
   "cell_type": "code",
   "source": "MODEL=\"llama3.2\"",
   "id": "32cbb8193001cca3",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T00:53:27.810705Z",
     "start_time": "2025-10-05T00:53:26.681205Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain import hub\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.document_loaders import WebBaseLoader"
   ],
   "id": "9bd4c0aa856c3e9c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T00:53:46.071990Z",
     "start_time": "2025-10-05T00:53:46.062861Z"
    }
   },
   "cell_type": "code",
   "source": [
    "anamoly_links=[\n",
    "    \"https://medium.com/simform-engineering/anomaly-detection-with-unsupervised-machine-learning-3bcf4c431aff\",\n",
    "    \"https://www.stratascratch.com/blog/machine-learning-algorithms-explained-anomaly-detection/\"\n",
    "]\n",
    "\n",
    "anamology_loader =WebBaseLoader(anamoly_links)"
   ],
   "id": "e80016d6015bdc61",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T00:53:48.554490Z",
     "start_time": "2025-10-05T00:53:47.588422Z"
    }
   },
   "cell_type": "code",
   "source": [
    "anamoly_langchain_docs = anamology_loader.load_and_split()\n",
    "anamoly_langchain_docs"
   ],
   "id": "6744b9d73755df8e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://medium.com/simform-engineering/anomaly-detection-with-unsupervised-machine-learning-3bcf4c431aff', 'title': 'Anomaly Detection with Unsupervised Machine Learning | by Hiraltalsaniya | Simform Engineering | Medium', 'description': 'Anomaly Detection with Unsupervised Machine Learning Detecting Outliers and Unusual Data Patterns with Unsupervised Learning In an era of big data, anomaly detection has become a crucial capability …', 'language': 'en'}, page_content='Anomaly Detection with Unsupervised Machine Learning | by Hiraltalsaniya | Simform Engineering | MediumSitemapOpen in appSign upSign inMedium LogoWriteSearchSign upSign inSimform Engineering·Our Engineering blog gives an inside look at our technologies from the perspective of our engineers.Anomaly Detection with Unsupervised Machine LearningHiraltalsaniya9 min read·Dec 22, 2023--1ListenShareDetecting Outliers and Unusual Data Patterns with Unsupervised LearningPress enter or click to view image in full sizeIn an era of big data, anomaly detection has become a crucial capability for unlocking hidden insights and ensuring data integrity. This blog dives into the world of unsupervised machine learning techniques to detect outliers efficiently without labeled data.We introduce key anomaly detection concepts, demonstrate anomaly detection methodologies and use cases, compare supervised and unsupervised models, and provide a step-by-step implementation guide using DBSCAN in Python.What is an anomaly?An anomaly is basically something that’s unusual, doesn’t fit the usual pattern, or stands out because it’s different in a specific category or situation. To explain it simply, let’s look at some clear examples:Think about a collection of smartphones, mostly from Samsung, and then there’s an iPhone. The iPhone is an anomaly because it’s a different brand.Imagine you have a bunch of pens, but one of them is a fancy fountain pen instead of a regular ballpoint pen. That fountain pen is an anomaly because it’s not like the others.What is anomaly detection?Anomaly detection is a technique used to identify data points that are significantly different or “outliers” when compared to the majority of the data in a dataset.Anomaly detection is about finding data points that are different from what is considered normal or expected, and it relies on historical data or established knowledge to determine what falls within the usual range. It plays a crucial role in ensuring the quality and security of data in various domains.Press enter or click to view image in full sizeExample of anomaly detection in server logs:Normal behavior:Website traffic follows a regular pattern.Requests per minute show a predictable trend, with slight increases during peak hours.Anomaly:Suddenly, there is an unusual, significant surge in traffic.This spike in requests per minute is an anomaly in the server logs.Anomaly detection use casesHere are some diverse applications of anomaly detection using machine learning:Event detection in sensor networksManufacturing quality controlHealthcare monitoringSocial media monitoringFraud detectionNetwork intrusion detectionHealthcare monitoringInsurance claim analysisCybersecurity threat detectionIdentity theftTraffic monitoringNetwork intrusion detectionData breachesIntrusion detectionVideo surveillanceThe three settings for anomaly detection, as described by Dr. Thomas Dietterich and his team at Oregon State University in 2018:Supervised Anomaly Detection: In this setting, the anomaly detection model is trained on a labeled dataset, which means that each data point is explicitly marked as either normal or anomalous. The model learns the characteristics of normal data and uses this knowledge to detect anomalies in new, unseen data. Supervised anomaly detection is effective when you have a reliable labeled dataset for training, and it is suitable for scenarios where anomalies are relatively easy to define and identify.ML Algorithm for structured data:- Bayesian networks- k-nearest neighbors (KNN)- Decision treesClean Anomaly Detection: Clean anomaly detection refers to situations where the data is mostly clean and free from noise or errors, making it easier to detect anomalies. In this setting, the focus is on identifying significant deviations from the established normal patterns. Clean anomaly detection is commonly used in applications where the data is well-structured and follows predictable patterns, such as fraud detection in'),\n",
       " Document(metadata={'source': 'https://medium.com/simform-engineering/anomaly-detection-with-unsupervised-machine-learning-3bcf4c431aff', 'title': 'Anomaly Detection with Unsupervised Machine Learning | by Hiraltalsaniya | Simform Engineering | Medium', 'description': 'Anomaly Detection with Unsupervised Machine Learning Detecting Outliers and Unusual Data Patterns with Unsupervised Learning In an era of big data, anomaly detection has become a crucial capability …', 'language': 'en'}, page_content='from the established normal patterns. Clean anomaly detection is commonly used in applications where the data is well-structured and follows predictable patterns, such as fraud detection in financial transactions or quality control in manufacturing.Unsupervised Anomaly Detection: Unsupervised anomaly detection occurs when there are no labeled anomalies in the training data, and the model needs to identify anomalies without prior knowledge of what constitutes an anomaly. The model’s task is to find data points that deviate significantly from the majority of the data, making it suitable for cases where anomalies are rare or poorly understood. ML algorithm for unstructured data:- K-means- One-class support vector machineHere are some common approaches to anomaly detection:Press enter or click to view image in full sizeStatistical methods:Z-Score/Standard Score: This method measures how many standard deviations a data point is away from the mean. Points that fall far from the mean are considered anomalies.Percentiles: Identifying anomalies based on percentiles or quantiles, where values below or above a certain threshold are considered outliers.Machine learning algorithms:Isolation Forest: An ensemble learning method that builds a tree structure to isolate anomalies efficiently.One-Class SVM: A support vector machine (SVM) model trained to classify data points as normal or outliers.K-Nearest Neighbors (KNN): Assigns an anomaly score based on the distance to the K-nearest neighbors, with distant points being potential anomalies.Autoencoders: Neural networks designed to learn a compressed representation of data, where reconstruction error can be used to identify anomalies.Clustering methods:DBSCAN (Density-Based Spatial Clustering of Applications with Noise): Clusters data points based on their density, with points that do not belong to any cluster considered outliers.K-Means Clustering: Data points that do not belong to well-defined clusters may be considered anomalies.Time-series analysis:Moving Averages: Identifying anomalies based on deviations from the moving average or exponential moving average.Seasonal Decomposition: Decomposing a time series into its trend, seasonal, and residual components, with anomalies often detected in the residual component.Proximity-based approaches:Mahalanobis Distance: Measures the distance of data points from the center of the data distribution, considering correlations between features.Local Outlier Factor (LOF): Computes the local density deviation of a data point compared to its neighbors, identifying regions of different densities.Let’s dive a bit deeper into how DBSCAN works with a simple analogyDBSCAN (Density-Based Spatial Clustering of Applications with Noise) is a clever way to find unusual or outlier data points in a group of data. Imagine you have a bunch of points on a map, and you want to find the weird ones that don’t really fit into any group.Here’s how DBSCAN works:Step 1: Select a starting pointBegin by randomly selecting a data point from your dataset.Step 2: Define a radius (Epsilon) and minimum number of oints (Min_Samples)Specify two important values:Epsilon (a radius around the selected point).Min_Samples (the minimum number of data points that should be within this radius to form a cluster)Step 3: Check neighboring pointsExamine all data points within the defined radius (Epsilon) around the selected point.Step 4: Form a clusterIf there are at least as many data points within the Epsilon radius as specified by Min_Samples, consider the selected point and these nearby points as a cluster.Step 5: Expand the clusterNow, for each point within this newly formed cluster, repeat the process. Check for nearby points within the Epsilon radius.If additional points are found, add them to the cluster. This process continues iteratively, expanding the cluster until no more points can be added.Step 6: Identify outliers (noise)Any data points that are not included in any cluster after the'),\n",
       " Document(metadata={'source': 'https://medium.com/simform-engineering/anomaly-detection-with-unsupervised-machine-learning-3bcf4c431aff', 'title': 'Anomaly Detection with Unsupervised Machine Learning | by Hiraltalsaniya | Simform Engineering | Medium', 'description': 'Anomaly Detection with Unsupervised Machine Learning Detecting Outliers and Unusual Data Patterns with Unsupervised Learning In an era of big data, anomaly detection has become a crucial capability …', 'language': 'en'}, page_content='cluster. This process continues iteratively, expanding the cluster until no more points can be added.Step 6: Identify outliers (noise)Any data points that are not included in any cluster after the expansion process are labeled as outliers or noise. These points do not belong to any cluster.Imagine you have a field with a bunch of people scattered around, and you want to organize a game of tag. Some people are standing close together, and others are standing alone. DBSCAN helps you identify two things:Groups of Players: It starts by picking a person, any person, and puts an imaginary hula hoop around them (this is like setting a maximum distance). Now, it checks how many other people are inside that hula hoop. If there are enough (more than a certain number you decide in advance), it forms a group. This group is like a team of players playing tag.Lonely Players: After forming that group, it picks a person within that group, puts a hula hoop around them, and checks if there are more people inside. If yes, it adds them to the group. This process continues until there are no more people to add to that group.Now, here’s the cool part: Anyone who doesn’t end up in a group is the outlier or the “lonely player.” These are the people who don’t belong to any team, or in data terms, they are the outliers.To apply DBSCAN for outlier detection in Python using Scikit-Learn, we begin by importing the necessary libraries and modules, as follows:Step 1: Import necessary librariesThe code starts by importing the required Python libraries, including NumPy for numerical operations, Matplotlib for data visualization, and the DBSCAN class from scikit-learn for implementing the DBSCAN algorithm.import numpy as npimport matplotlib.pyplot as pltfrom sklearn.cluster import DBSCANfrom sklearn.datasets import make_blobsStep 2: Create a synthetic dataset# Create a synthetic dataset with normal and anomalous data pointsn_samples = 300X, y = make_blobs(n_samples=n_samples, centers=2, random_state=42, cluster_std=1.0)anomalies = np.array([[5, 5], [6, 6], [7, 7]])In this step, a synthetic dataset is generated to illustrate the concept. The dataset is created using the make_blobs function, producing two clusters of data points with some isolated anomalies.n_samples determines the total number of data points, and the centers parameter specifies the number of clusters (2, in this case).The anomalies variable is an array of manually created anomalous data points.Step 3: Combine normal and anomalous data# Combine the normal data and anomaliesX = np.vstack([X, anomalies])The normal data and anomalies are combined into a single dataset represented by the X array using np.vstack.Step 4: Visualize the dataset# Visualize the datasetplt.scatter(X[:, 0], X[:, 1], c=\\'b\\', marker=\\'o\\', s=25)plt.title(\"Synthetic Dataset\")plt.show()The code plots the dataset to provide a visual representation. It uses Matplotlib to create a scatter plot, where normal data points are marked in blue circles.The resulting plot visually shows two clusters and some isolated red crosses representing the anomalies.Step 5: Apply DBSCAN for anomaly detection# Apply DBSCAN for anomaly detection with increased epsilondbscan = DBSCAN(eps=1, min_samples=41)  # Increase epslabels = dbscan.fit_predict(X)# Anomalies are considered as points with label -1anomalies = X[labels == -1]DBSCAN is applied for anomaly detection using the DBSCAN class from scikit-learn. The parameters eps (epsilon) and min_samples control the algorithm\\'s behavior.The eps parameter sets the radius within which points are considered neighbors.The min_samples parameter defines the minimum number of points required to form a cluster.The code then fits the DBSCAN model to the dataset using fit_predict to obtain cluster labels for each data point.Step 6: Identify anomalies# Anomalies are considered as points with label -1anomalies = X[labels == -1]Anomalies are identified by finding data points labeled as -1. These points do not belong to'),\n",
       " Document(metadata={'source': 'https://medium.com/simform-engineering/anomaly-detection-with-unsupervised-machine-learning-3bcf4c431aff', 'title': 'Anomaly Detection with Unsupervised Machine Learning | by Hiraltalsaniya | Simform Engineering | Medium', 'description': 'Anomaly Detection with Unsupervised Machine Learning Detecting Outliers and Unusual Data Patterns with Unsupervised Learning In an era of big data, anomaly detection has become a crucial capability …', 'language': 'en'}, page_content='6: Identify anomalies# Anomalies are considered as points with label -1anomalies = X[labels == -1]Anomalies are identified by finding data points labeled as -1. These points do not belong to any cluster and are considered outliers or anomalies.Step 7: Visualize the anomalies# Visualize the anomaliesplt.scatter(X[:, 0], X[:, 1], c=\\'b\\', marker=\\'o\\', s=25)plt.scatter(anomalies[:, 0], anomalies[:, 1], c=\\'r\\', marker=\\'x\\', s=50, label=\\'Anomalies\\')plt.title(\"Anomaly Detection with DBSCAN (Anomalies Outside Clusters)\")plt.legend()plt.show()The code plots the anomalies found by DBSCAN in red crosses on top of the original data points.This visualization helps to highlight the anomalies detected by the algorithm.Step 8: Print the identified anomalies# Print the identified anomaliesprint(\"Identified Anomalies:\")print(anomalies)The code concludes by printing the coordinates of the identified anomalies, allowing you to see the specific data points classified as anomalies by the DBSCAN algorithm.By following these steps, you can effectively identify an anomaly with DBSCAN and visualize its results.ConclusionDBSCAN is a valuable tool for anomaly detection, offering a data-driven approach to uncovering outliers in complex datasets. By following the step-by-step guide and code provided in this blog post, you can integrate DBSCAN into your own data analysis projects, enhance your anomaly detection capabilities, and make more informed decisions based on the unique insights that outliers can provide.Follow Simform Engineering to keep yourself updated with the latest trends in the technology horizon. Follow us: Twitter | LinkedInReferencesAnomaly detection with practical exampleImagine you are working as a sysadmin in a fintech company. There can be an issue in the front-end that stops your…towardsdatascience.comUnsupervised learning for anomaly detection - CENTUM DigitalLa identificación de anomalías puede suponer una gran ventaja para tu empresa. Aquí te contamos cómo el aprendizaje no…centum.comHow to do Anomaly Detection using Machine Learning in Python?Anomaly Detection using Machine Learning in Python Example | ProjectProwww.projectpro.ioAlgorithm selection for Anomaly DetectionAnomalies can be defined as observations which deviate sufficiently from most observations in the data set to consider…medium.comUnsupervised LearningAnomaly DetectionMachine LearningDbscan Algorithm----1Published in Simform Engineering1.4K followers·Last published\\xa01 day agoOur Engineering blog gives an inside look at our technologies from the perspective of our engineers.Written by Hiraltalsaniya20 followers·28 followingResponses (1)See all responsesHelpStatusAboutCareersPressBlogPrivacyRulesTermsText to speech'),\n",
       " Document(metadata={'source': 'https://www.stratascratch.com/blog/machine-learning-algorithms-explained-anomaly-detection/', 'title': 'Vercel Security Checkpoint', 'language': 'en'}, page_content=\"Vercel Security Checkpoint                  We're verifying your browser  Website owner? Click here to fix       Vercel Security Checkpoint | iad1::1759625628-DDjT8AGoDNVohG6hOhUWnrzIaph0TOCE                     Enable JavaScript to continue    Vercel Security Checkpoint | iad1::1759625628-DDjT8AGoDNVohG6hOhUWnrzIaph0TOCE\")]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T00:53:49.761867Z",
     "start_time": "2025-10-05T00:53:49.755097Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.documents import Document\n",
    "from collections import defaultdict\n",
    "\n",
    "#Group docs by source\n",
    "grouped_docs = defaultdict(list)\n",
    "for doc in anamoly_langchain_docs:\n",
    "    source = doc.metadata.get('source', '')\n",
    "    grouped_docs[source].append(doc)\n"
   ],
   "id": "26206867e89c330d",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T00:53:52.749466Z",
     "start_time": "2025-10-05T00:53:52.742344Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for k,v in grouped_docs.items():\n",
    "    print(f\"[{k=}] {v=}\")"
   ],
   "id": "7401318962e10f47",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[k='https://medium.com/simform-engineering/anomaly-detection-with-unsupervised-machine-learning-3bcf4c431aff'] v=[Document(metadata={'source': 'https://medium.com/simform-engineering/anomaly-detection-with-unsupervised-machine-learning-3bcf4c431aff', 'title': 'Anomaly Detection with Unsupervised Machine Learning | by Hiraltalsaniya | Simform Engineering | Medium', 'description': 'Anomaly Detection with Unsupervised Machine Learning Detecting Outliers and Unusual Data Patterns with Unsupervised Learning In an era of big data, anomaly detection has become a crucial capability …', 'language': 'en'}, page_content='Anomaly Detection with Unsupervised Machine Learning | by Hiraltalsaniya | Simform Engineering | MediumSitemapOpen in appSign upSign inMedium LogoWriteSearchSign upSign inSimform Engineering·Our Engineering blog gives an inside look at our technologies from the perspective of our engineers.Anomaly Detection with Unsupervised Machine LearningHiraltalsaniya9 min read·Dec 22, 2023--1ListenShareDetecting Outliers and Unusual Data Patterns with Unsupervised LearningPress enter or click to view image in full sizeIn an era of big data, anomaly detection has become a crucial capability for unlocking hidden insights and ensuring data integrity. This blog dives into the world of unsupervised machine learning techniques to detect outliers efficiently without labeled data.We introduce key anomaly detection concepts, demonstrate anomaly detection methodologies and use cases, compare supervised and unsupervised models, and provide a step-by-step implementation guide using DBSCAN in Python.What is an anomaly?An anomaly is basically something that’s unusual, doesn’t fit the usual pattern, or stands out because it’s different in a specific category or situation. To explain it simply, let’s look at some clear examples:Think about a collection of smartphones, mostly from Samsung, and then there’s an iPhone. The iPhone is an anomaly because it’s a different brand.Imagine you have a bunch of pens, but one of them is a fancy fountain pen instead of a regular ballpoint pen. That fountain pen is an anomaly because it’s not like the others.What is anomaly detection?Anomaly detection is a technique used to identify data points that are significantly different or “outliers” when compared to the majority of the data in a dataset.Anomaly detection is about finding data points that are different from what is considered normal or expected, and it relies on historical data or established knowledge to determine what falls within the usual range. It plays a crucial role in ensuring the quality and security of data in various domains.Press enter or click to view image in full sizeExample of anomaly detection in server logs:Normal behavior:Website traffic follows a regular pattern.Requests per minute show a predictable trend, with slight increases during peak hours.Anomaly:Suddenly, there is an unusual, significant surge in traffic.This spike in requests per minute is an anomaly in the server logs.Anomaly detection use casesHere are some diverse applications of anomaly detection using machine learning:Event detection in sensor networksManufacturing quality controlHealthcare monitoringSocial media monitoringFraud detectionNetwork intrusion detectionHealthcare monitoringInsurance claim analysisCybersecurity threat detectionIdentity theftTraffic monitoringNetwork intrusion detectionData breachesIntrusion detectionVideo surveillanceThe three settings for anomaly detection, as described by Dr. Thomas Dietterich and his team at Oregon State University in 2018:Supervised Anomaly Detection: In this setting, the anomaly detection model is trained on a labeled dataset, which means that each data point is explicitly marked as either normal or anomalous. The model learns the characteristics of normal data and uses this knowledge to detect anomalies in new, unseen data. Supervised anomaly detection is effective when you have a reliable labeled dataset for training, and it is suitable for scenarios where anomalies are relatively easy to define and identify.ML Algorithm for structured data:- Bayesian networks- k-nearest neighbors (KNN)- Decision treesClean Anomaly Detection: Clean anomaly detection refers to situations where the data is mostly clean and free from noise or errors, making it easier to detect anomalies. In this setting, the focus is on identifying significant deviations from the established normal patterns. Clean anomaly detection is commonly used in applications where the data is well-structured and follows predictable patterns, such as fraud detection in'), Document(metadata={'source': 'https://medium.com/simform-engineering/anomaly-detection-with-unsupervised-machine-learning-3bcf4c431aff', 'title': 'Anomaly Detection with Unsupervised Machine Learning | by Hiraltalsaniya | Simform Engineering | Medium', 'description': 'Anomaly Detection with Unsupervised Machine Learning Detecting Outliers and Unusual Data Patterns with Unsupervised Learning In an era of big data, anomaly detection has become a crucial capability …', 'language': 'en'}, page_content='from the established normal patterns. Clean anomaly detection is commonly used in applications where the data is well-structured and follows predictable patterns, such as fraud detection in financial transactions or quality control in manufacturing.Unsupervised Anomaly Detection: Unsupervised anomaly detection occurs when there are no labeled anomalies in the training data, and the model needs to identify anomalies without prior knowledge of what constitutes an anomaly. The model’s task is to find data points that deviate significantly from the majority of the data, making it suitable for cases where anomalies are rare or poorly understood. ML algorithm for unstructured data:- K-means- One-class support vector machineHere are some common approaches to anomaly detection:Press enter or click to view image in full sizeStatistical methods:Z-Score/Standard Score: This method measures how many standard deviations a data point is away from the mean. Points that fall far from the mean are considered anomalies.Percentiles: Identifying anomalies based on percentiles or quantiles, where values below or above a certain threshold are considered outliers.Machine learning algorithms:Isolation Forest: An ensemble learning method that builds a tree structure to isolate anomalies efficiently.One-Class SVM: A support vector machine (SVM) model trained to classify data points as normal or outliers.K-Nearest Neighbors (KNN): Assigns an anomaly score based on the distance to the K-nearest neighbors, with distant points being potential anomalies.Autoencoders: Neural networks designed to learn a compressed representation of data, where reconstruction error can be used to identify anomalies.Clustering methods:DBSCAN (Density-Based Spatial Clustering of Applications with Noise): Clusters data points based on their density, with points that do not belong to any cluster considered outliers.K-Means Clustering: Data points that do not belong to well-defined clusters may be considered anomalies.Time-series analysis:Moving Averages: Identifying anomalies based on deviations from the moving average or exponential moving average.Seasonal Decomposition: Decomposing a time series into its trend, seasonal, and residual components, with anomalies often detected in the residual component.Proximity-based approaches:Mahalanobis Distance: Measures the distance of data points from the center of the data distribution, considering correlations between features.Local Outlier Factor (LOF): Computes the local density deviation of a data point compared to its neighbors, identifying regions of different densities.Let’s dive a bit deeper into how DBSCAN works with a simple analogyDBSCAN (Density-Based Spatial Clustering of Applications with Noise) is a clever way to find unusual or outlier data points in a group of data. Imagine you have a bunch of points on a map, and you want to find the weird ones that don’t really fit into any group.Here’s how DBSCAN works:Step 1: Select a starting pointBegin by randomly selecting a data point from your dataset.Step 2: Define a radius (Epsilon) and minimum number of oints (Min_Samples)Specify two important values:Epsilon (a radius around the selected point).Min_Samples (the minimum number of data points that should be within this radius to form a cluster)Step 3: Check neighboring pointsExamine all data points within the defined radius (Epsilon) around the selected point.Step 4: Form a clusterIf there are at least as many data points within the Epsilon radius as specified by Min_Samples, consider the selected point and these nearby points as a cluster.Step 5: Expand the clusterNow, for each point within this newly formed cluster, repeat the process. Check for nearby points within the Epsilon radius.If additional points are found, add them to the cluster. This process continues iteratively, expanding the cluster until no more points can be added.Step 6: Identify outliers (noise)Any data points that are not included in any cluster after the'), Document(metadata={'source': 'https://medium.com/simform-engineering/anomaly-detection-with-unsupervised-machine-learning-3bcf4c431aff', 'title': 'Anomaly Detection with Unsupervised Machine Learning | by Hiraltalsaniya | Simform Engineering | Medium', 'description': 'Anomaly Detection with Unsupervised Machine Learning Detecting Outliers and Unusual Data Patterns with Unsupervised Learning In an era of big data, anomaly detection has become a crucial capability …', 'language': 'en'}, page_content='cluster. This process continues iteratively, expanding the cluster until no more points can be added.Step 6: Identify outliers (noise)Any data points that are not included in any cluster after the expansion process are labeled as outliers or noise. These points do not belong to any cluster.Imagine you have a field with a bunch of people scattered around, and you want to organize a game of tag. Some people are standing close together, and others are standing alone. DBSCAN helps you identify two things:Groups of Players: It starts by picking a person, any person, and puts an imaginary hula hoop around them (this is like setting a maximum distance). Now, it checks how many other people are inside that hula hoop. If there are enough (more than a certain number you decide in advance), it forms a group. This group is like a team of players playing tag.Lonely Players: After forming that group, it picks a person within that group, puts a hula hoop around them, and checks if there are more people inside. If yes, it adds them to the group. This process continues until there are no more people to add to that group.Now, here’s the cool part: Anyone who doesn’t end up in a group is the outlier or the “lonely player.” These are the people who don’t belong to any team, or in data terms, they are the outliers.To apply DBSCAN for outlier detection in Python using Scikit-Learn, we begin by importing the necessary libraries and modules, as follows:Step 1: Import necessary librariesThe code starts by importing the required Python libraries, including NumPy for numerical operations, Matplotlib for data visualization, and the DBSCAN class from scikit-learn for implementing the DBSCAN algorithm.import numpy as npimport matplotlib.pyplot as pltfrom sklearn.cluster import DBSCANfrom sklearn.datasets import make_blobsStep 2: Create a synthetic dataset# Create a synthetic dataset with normal and anomalous data pointsn_samples = 300X, y = make_blobs(n_samples=n_samples, centers=2, random_state=42, cluster_std=1.0)anomalies = np.array([[5, 5], [6, 6], [7, 7]])In this step, a synthetic dataset is generated to illustrate the concept. The dataset is created using the make_blobs function, producing two clusters of data points with some isolated anomalies.n_samples determines the total number of data points, and the centers parameter specifies the number of clusters (2, in this case).The anomalies variable is an array of manually created anomalous data points.Step 3: Combine normal and anomalous data# Combine the normal data and anomaliesX = np.vstack([X, anomalies])The normal data and anomalies are combined into a single dataset represented by the X array using np.vstack.Step 4: Visualize the dataset# Visualize the datasetplt.scatter(X[:, 0], X[:, 1], c=\\'b\\', marker=\\'o\\', s=25)plt.title(\"Synthetic Dataset\")plt.show()The code plots the dataset to provide a visual representation. It uses Matplotlib to create a scatter plot, where normal data points are marked in blue circles.The resulting plot visually shows two clusters and some isolated red crosses representing the anomalies.Step 5: Apply DBSCAN for anomaly detection# Apply DBSCAN for anomaly detection with increased epsilondbscan = DBSCAN(eps=1, min_samples=41)  # Increase epslabels = dbscan.fit_predict(X)# Anomalies are considered as points with label -1anomalies = X[labels == -1]DBSCAN is applied for anomaly detection using the DBSCAN class from scikit-learn. The parameters eps (epsilon) and min_samples control the algorithm\\'s behavior.The eps parameter sets the radius within which points are considered neighbors.The min_samples parameter defines the minimum number of points required to form a cluster.The code then fits the DBSCAN model to the dataset using fit_predict to obtain cluster labels for each data point.Step 6: Identify anomalies# Anomalies are considered as points with label -1anomalies = X[labels == -1]Anomalies are identified by finding data points labeled as -1. These points do not belong to'), Document(metadata={'source': 'https://medium.com/simform-engineering/anomaly-detection-with-unsupervised-machine-learning-3bcf4c431aff', 'title': 'Anomaly Detection with Unsupervised Machine Learning | by Hiraltalsaniya | Simform Engineering | Medium', 'description': 'Anomaly Detection with Unsupervised Machine Learning Detecting Outliers and Unusual Data Patterns with Unsupervised Learning In an era of big data, anomaly detection has become a crucial capability …', 'language': 'en'}, page_content='6: Identify anomalies# Anomalies are considered as points with label -1anomalies = X[labels == -1]Anomalies are identified by finding data points labeled as -1. These points do not belong to any cluster and are considered outliers or anomalies.Step 7: Visualize the anomalies# Visualize the anomaliesplt.scatter(X[:, 0], X[:, 1], c=\\'b\\', marker=\\'o\\', s=25)plt.scatter(anomalies[:, 0], anomalies[:, 1], c=\\'r\\', marker=\\'x\\', s=50, label=\\'Anomalies\\')plt.title(\"Anomaly Detection with DBSCAN (Anomalies Outside Clusters)\")plt.legend()plt.show()The code plots the anomalies found by DBSCAN in red crosses on top of the original data points.This visualization helps to highlight the anomalies detected by the algorithm.Step 8: Print the identified anomalies# Print the identified anomaliesprint(\"Identified Anomalies:\")print(anomalies)The code concludes by printing the coordinates of the identified anomalies, allowing you to see the specific data points classified as anomalies by the DBSCAN algorithm.By following these steps, you can effectively identify an anomaly with DBSCAN and visualize its results.ConclusionDBSCAN is a valuable tool for anomaly detection, offering a data-driven approach to uncovering outliers in complex datasets. By following the step-by-step guide and code provided in this blog post, you can integrate DBSCAN into your own data analysis projects, enhance your anomaly detection capabilities, and make more informed decisions based on the unique insights that outliers can provide.Follow Simform Engineering to keep yourself updated with the latest trends in the technology horizon. Follow us: Twitter | LinkedInReferencesAnomaly detection with practical exampleImagine you are working as a sysadmin in a fintech company. There can be an issue in the front-end that stops your…towardsdatascience.comUnsupervised learning for anomaly detection - CENTUM DigitalLa identificación de anomalías puede suponer una gran ventaja para tu empresa. Aquí te contamos cómo el aprendizaje no…centum.comHow to do Anomaly Detection using Machine Learning in Python?Anomaly Detection using Machine Learning in Python Example | ProjectProwww.projectpro.ioAlgorithm selection for Anomaly DetectionAnomalies can be defined as observations which deviate sufficiently from most observations in the data set to consider…medium.comUnsupervised LearningAnomaly DetectionMachine LearningDbscan Algorithm----1Published in Simform Engineering1.4K followers·Last published\\xa01 day agoOur Engineering blog gives an inside look at our technologies from the perspective of our engineers.Written by Hiraltalsaniya20 followers·28 followingResponses (1)See all responsesHelpStatusAboutCareersPressBlogPrivacyRulesTermsText to speech')]\n",
      "[k='https://www.stratascratch.com/blog/machine-learning-algorithms-explained-anomaly-detection/'] v=[Document(metadata={'source': 'https://www.stratascratch.com/blog/machine-learning-algorithms-explained-anomaly-detection/', 'title': 'Vercel Security Checkpoint', 'language': 'en'}, page_content=\"Vercel Security Checkpoint                  We're verifying your browser  Website owner? Click here to fix       Vercel Security Checkpoint | iad1::1759625628-DDjT8AGoDNVohG6hOhUWnrzIaph0TOCE                     Enable JavaScript to continue    Vercel Security Checkpoint | iad1::1759625628-DDjT8AGoDNVohG6hOhUWnrzIaph0TOCE\")]\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T00:53:54.451695Z",
     "start_time": "2025-10-05T00:53:54.438781Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Combine documents with the same source\n",
    "combined_docs = []\n",
    "for source, docs in grouped_docs.items():\n",
    "    combined_content = \"\\n\".join(doc.page_content for doc in docs)\n",
    "    combined_metadata={}\n",
    "    # combined_metadata = docs[0].metadata.copy()  # Use metadata from the first document\n",
    "    combined_metadata['num_chunks'] = len(docs)  # Add number of original chunks\n",
    "    combined_docs.append(Document(page_content=combined_content, metadata=combined_metadata))\n",
    "\n",
    "# Replace langchain_docs with the combined documents\n",
    "langchain_docs = combined_docs"
   ],
   "id": "58a6b46a44b88b0",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T00:53:58.063245Z",
     "start_time": "2025-10-05T00:53:58.055391Z"
    }
   },
   "cell_type": "code",
   "source": "len(langchain_docs)",
   "id": "848c41836885ef0f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T00:53:59.233310Z",
     "start_time": "2025-10-05T00:53:59.225321Z"
    }
   },
   "cell_type": "code",
   "source": [
    "anamoly_doc_obj=langchain_docs[0]\n",
    "anamoly_doc_obj"
   ],
   "id": "4db013497bf51896",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'num_chunks': 4}, page_content='Anomaly Detection with Unsupervised Machine Learning | by Hiraltalsaniya | Simform Engineering | MediumSitemapOpen in appSign upSign inMedium LogoWriteSearchSign upSign inSimform Engineering·Our Engineering blog gives an inside look at our technologies from the perspective of our engineers.Anomaly Detection with Unsupervised Machine LearningHiraltalsaniya9 min read·Dec 22, 2023--1ListenShareDetecting Outliers and Unusual Data Patterns with Unsupervised LearningPress enter or click to view image in full sizeIn an era of big data, anomaly detection has become a crucial capability for unlocking hidden insights and ensuring data integrity. This blog dives into the world of unsupervised machine learning techniques to detect outliers efficiently without labeled data.We introduce key anomaly detection concepts, demonstrate anomaly detection methodologies and use cases, compare supervised and unsupervised models, and provide a step-by-step implementation guide using DBSCAN in Python.What is an anomaly?An anomaly is basically something that’s unusual, doesn’t fit the usual pattern, or stands out because it’s different in a specific category or situation. To explain it simply, let’s look at some clear examples:Think about a collection of smartphones, mostly from Samsung, and then there’s an iPhone. The iPhone is an anomaly because it’s a different brand.Imagine you have a bunch of pens, but one of them is a fancy fountain pen instead of a regular ballpoint pen. That fountain pen is an anomaly because it’s not like the others.What is anomaly detection?Anomaly detection is a technique used to identify data points that are significantly different or “outliers” when compared to the majority of the data in a dataset.Anomaly detection is about finding data points that are different from what is considered normal or expected, and it relies on historical data or established knowledge to determine what falls within the usual range. It plays a crucial role in ensuring the quality and security of data in various domains.Press enter or click to view image in full sizeExample of anomaly detection in server logs:Normal behavior:Website traffic follows a regular pattern.Requests per minute show a predictable trend, with slight increases during peak hours.Anomaly:Suddenly, there is an unusual, significant surge in traffic.This spike in requests per minute is an anomaly in the server logs.Anomaly detection use casesHere are some diverse applications of anomaly detection using machine learning:Event detection in sensor networksManufacturing quality controlHealthcare monitoringSocial media monitoringFraud detectionNetwork intrusion detectionHealthcare monitoringInsurance claim analysisCybersecurity threat detectionIdentity theftTraffic monitoringNetwork intrusion detectionData breachesIntrusion detectionVideo surveillanceThe three settings for anomaly detection, as described by Dr. Thomas Dietterich and his team at Oregon State University in 2018:Supervised Anomaly Detection: In this setting, the anomaly detection model is trained on a labeled dataset, which means that each data point is explicitly marked as either normal or anomalous. The model learns the characteristics of normal data and uses this knowledge to detect anomalies in new, unseen data. Supervised anomaly detection is effective when you have a reliable labeled dataset for training, and it is suitable for scenarios where anomalies are relatively easy to define and identify.ML Algorithm for structured data:- Bayesian networks- k-nearest neighbors (KNN)- Decision treesClean Anomaly Detection: Clean anomaly detection refers to situations where the data is mostly clean and free from noise or errors, making it easier to detect anomalies. In this setting, the focus is on identifying significant deviations from the established normal patterns. Clean anomaly detection is commonly used in applications where the data is well-structured and follows predictable patterns, such as fraud detection in\\nfrom the established normal patterns. Clean anomaly detection is commonly used in applications where the data is well-structured and follows predictable patterns, such as fraud detection in financial transactions or quality control in manufacturing.Unsupervised Anomaly Detection: Unsupervised anomaly detection occurs when there are no labeled anomalies in the training data, and the model needs to identify anomalies without prior knowledge of what constitutes an anomaly. The model’s task is to find data points that deviate significantly from the majority of the data, making it suitable for cases where anomalies are rare or poorly understood. ML algorithm for unstructured data:- K-means- One-class support vector machineHere are some common approaches to anomaly detection:Press enter or click to view image in full sizeStatistical methods:Z-Score/Standard Score: This method measures how many standard deviations a data point is away from the mean. Points that fall far from the mean are considered anomalies.Percentiles: Identifying anomalies based on percentiles or quantiles, where values below or above a certain threshold are considered outliers.Machine learning algorithms:Isolation Forest: An ensemble learning method that builds a tree structure to isolate anomalies efficiently.One-Class SVM: A support vector machine (SVM) model trained to classify data points as normal or outliers.K-Nearest Neighbors (KNN): Assigns an anomaly score based on the distance to the K-nearest neighbors, with distant points being potential anomalies.Autoencoders: Neural networks designed to learn a compressed representation of data, where reconstruction error can be used to identify anomalies.Clustering methods:DBSCAN (Density-Based Spatial Clustering of Applications with Noise): Clusters data points based on their density, with points that do not belong to any cluster considered outliers.K-Means Clustering: Data points that do not belong to well-defined clusters may be considered anomalies.Time-series analysis:Moving Averages: Identifying anomalies based on deviations from the moving average or exponential moving average.Seasonal Decomposition: Decomposing a time series into its trend, seasonal, and residual components, with anomalies often detected in the residual component.Proximity-based approaches:Mahalanobis Distance: Measures the distance of data points from the center of the data distribution, considering correlations between features.Local Outlier Factor (LOF): Computes the local density deviation of a data point compared to its neighbors, identifying regions of different densities.Let’s dive a bit deeper into how DBSCAN works with a simple analogyDBSCAN (Density-Based Spatial Clustering of Applications with Noise) is a clever way to find unusual or outlier data points in a group of data. Imagine you have a bunch of points on a map, and you want to find the weird ones that don’t really fit into any group.Here’s how DBSCAN works:Step 1: Select a starting pointBegin by randomly selecting a data point from your dataset.Step 2: Define a radius (Epsilon) and minimum number of oints (Min_Samples)Specify two important values:Epsilon (a radius around the selected point).Min_Samples (the minimum number of data points that should be within this radius to form a cluster)Step 3: Check neighboring pointsExamine all data points within the defined radius (Epsilon) around the selected point.Step 4: Form a clusterIf there are at least as many data points within the Epsilon radius as specified by Min_Samples, consider the selected point and these nearby points as a cluster.Step 5: Expand the clusterNow, for each point within this newly formed cluster, repeat the process. Check for nearby points within the Epsilon radius.If additional points are found, add them to the cluster. This process continues iteratively, expanding the cluster until no more points can be added.Step 6: Identify outliers (noise)Any data points that are not included in any cluster after the\\ncluster. This process continues iteratively, expanding the cluster until no more points can be added.Step 6: Identify outliers (noise)Any data points that are not included in any cluster after the expansion process are labeled as outliers or noise. These points do not belong to any cluster.Imagine you have a field with a bunch of people scattered around, and you want to organize a game of tag. Some people are standing close together, and others are standing alone. DBSCAN helps you identify two things:Groups of Players: It starts by picking a person, any person, and puts an imaginary hula hoop around them (this is like setting a maximum distance). Now, it checks how many other people are inside that hula hoop. If there are enough (more than a certain number you decide in advance), it forms a group. This group is like a team of players playing tag.Lonely Players: After forming that group, it picks a person within that group, puts a hula hoop around them, and checks if there are more people inside. If yes, it adds them to the group. This process continues until there are no more people to add to that group.Now, here’s the cool part: Anyone who doesn’t end up in a group is the outlier or the “lonely player.” These are the people who don’t belong to any team, or in data terms, they are the outliers.To apply DBSCAN for outlier detection in Python using Scikit-Learn, we begin by importing the necessary libraries and modules, as follows:Step 1: Import necessary librariesThe code starts by importing the required Python libraries, including NumPy for numerical operations, Matplotlib for data visualization, and the DBSCAN class from scikit-learn for implementing the DBSCAN algorithm.import numpy as npimport matplotlib.pyplot as pltfrom sklearn.cluster import DBSCANfrom sklearn.datasets import make_blobsStep 2: Create a synthetic dataset# Create a synthetic dataset with normal and anomalous data pointsn_samples = 300X, y = make_blobs(n_samples=n_samples, centers=2, random_state=42, cluster_std=1.0)anomalies = np.array([[5, 5], [6, 6], [7, 7]])In this step, a synthetic dataset is generated to illustrate the concept. The dataset is created using the make_blobs function, producing two clusters of data points with some isolated anomalies.n_samples determines the total number of data points, and the centers parameter specifies the number of clusters (2, in this case).The anomalies variable is an array of manually created anomalous data points.Step 3: Combine normal and anomalous data# Combine the normal data and anomaliesX = np.vstack([X, anomalies])The normal data and anomalies are combined into a single dataset represented by the X array using np.vstack.Step 4: Visualize the dataset# Visualize the datasetplt.scatter(X[:, 0], X[:, 1], c=\\'b\\', marker=\\'o\\', s=25)plt.title(\"Synthetic Dataset\")plt.show()The code plots the dataset to provide a visual representation. It uses Matplotlib to create a scatter plot, where normal data points are marked in blue circles.The resulting plot visually shows two clusters and some isolated red crosses representing the anomalies.Step 5: Apply DBSCAN for anomaly detection# Apply DBSCAN for anomaly detection with increased epsilondbscan = DBSCAN(eps=1, min_samples=41)  # Increase epslabels = dbscan.fit_predict(X)# Anomalies are considered as points with label -1anomalies = X[labels == -1]DBSCAN is applied for anomaly detection using the DBSCAN class from scikit-learn. The parameters eps (epsilon) and min_samples control the algorithm\\'s behavior.The eps parameter sets the radius within which points are considered neighbors.The min_samples parameter defines the minimum number of points required to form a cluster.The code then fits the DBSCAN model to the dataset using fit_predict to obtain cluster labels for each data point.Step 6: Identify anomalies# Anomalies are considered as points with label -1anomalies = X[labels == -1]Anomalies are identified by finding data points labeled as -1. These points do not belong to\\n6: Identify anomalies# Anomalies are considered as points with label -1anomalies = X[labels == -1]Anomalies are identified by finding data points labeled as -1. These points do not belong to any cluster and are considered outliers or anomalies.Step 7: Visualize the anomalies# Visualize the anomaliesplt.scatter(X[:, 0], X[:, 1], c=\\'b\\', marker=\\'o\\', s=25)plt.scatter(anomalies[:, 0], anomalies[:, 1], c=\\'r\\', marker=\\'x\\', s=50, label=\\'Anomalies\\')plt.title(\"Anomaly Detection with DBSCAN (Anomalies Outside Clusters)\")plt.legend()plt.show()The code plots the anomalies found by DBSCAN in red crosses on top of the original data points.This visualization helps to highlight the anomalies detected by the algorithm.Step 8: Print the identified anomalies# Print the identified anomaliesprint(\"Identified Anomalies:\")print(anomalies)The code concludes by printing the coordinates of the identified anomalies, allowing you to see the specific data points classified as anomalies by the DBSCAN algorithm.By following these steps, you can effectively identify an anomaly with DBSCAN and visualize its results.ConclusionDBSCAN is a valuable tool for anomaly detection, offering a data-driven approach to uncovering outliers in complex datasets. By following the step-by-step guide and code provided in this blog post, you can integrate DBSCAN into your own data analysis projects, enhance your anomaly detection capabilities, and make more informed decisions based on the unique insights that outliers can provide.Follow Simform Engineering to keep yourself updated with the latest trends in the technology horizon. Follow us: Twitter | LinkedInReferencesAnomaly detection with practical exampleImagine you are working as a sysadmin in a fintech company. There can be an issue in the front-end that stops your…towardsdatascience.comUnsupervised learning for anomaly detection - CENTUM DigitalLa identificación de anomalías puede suponer una gran ventaja para tu empresa. Aquí te contamos cómo el aprendizaje no…centum.comHow to do Anomaly Detection using Machine Learning in Python?Anomaly Detection using Machine Learning in Python Example | ProjectProwww.projectpro.ioAlgorithm selection for Anomaly DetectionAnomalies can be defined as observations which deviate sufficiently from most observations in the data set to consider…medium.comUnsupervised LearningAnomaly DetectionMachine LearningDbscan Algorithm----1Published in Simform Engineering1.4K followers·Last published\\xa01 day agoOur Engineering blog gives an inside look at our technologies from the perspective of our engineers.Written by Hiraltalsaniya20 followers·28 followingResponses (1)See all responsesHelpStatusAboutCareersPressBlogPrivacyRulesTermsText to speech')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T00:54:00.686123Z",
     "start_time": "2025-10-05T00:54:00.679137Z"
    }
   },
   "cell_type": "code",
   "source": "anamoly_doc_obj.page_content",
   "id": "65f285d5bdccf914",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Anomaly Detection with Unsupervised Machine Learning | by Hiraltalsaniya | Simform Engineering | MediumSitemapOpen in appSign upSign inMedium LogoWriteSearchSign upSign inSimform Engineering·Our Engineering blog gives an inside look at our technologies from the perspective of our engineers.Anomaly Detection with Unsupervised Machine LearningHiraltalsaniya9 min read·Dec 22, 2023--1ListenShareDetecting Outliers and Unusual Data Patterns with Unsupervised LearningPress enter or click to view image in full sizeIn an era of big data, anomaly detection has become a crucial capability for unlocking hidden insights and ensuring data integrity. This blog dives into the world of unsupervised machine learning techniques to detect outliers efficiently without labeled data.We introduce key anomaly detection concepts, demonstrate anomaly detection methodologies and use cases, compare supervised and unsupervised models, and provide a step-by-step implementation guide using DBSCAN in Python.What is an anomaly?An anomaly is basically something that’s unusual, doesn’t fit the usual pattern, or stands out because it’s different in a specific category or situation. To explain it simply, let’s look at some clear examples:Think about a collection of smartphones, mostly from Samsung, and then there’s an iPhone. The iPhone is an anomaly because it’s a different brand.Imagine you have a bunch of pens, but one of them is a fancy fountain pen instead of a regular ballpoint pen. That fountain pen is an anomaly because it’s not like the others.What is anomaly detection?Anomaly detection is a technique used to identify data points that are significantly different or “outliers” when compared to the majority of the data in a dataset.Anomaly detection is about finding data points that are different from what is considered normal or expected, and it relies on historical data or established knowledge to determine what falls within the usual range. It plays a crucial role in ensuring the quality and security of data in various domains.Press enter or click to view image in full sizeExample of anomaly detection in server logs:Normal behavior:Website traffic follows a regular pattern.Requests per minute show a predictable trend, with slight increases during peak hours.Anomaly:Suddenly, there is an unusual, significant surge in traffic.This spike in requests per minute is an anomaly in the server logs.Anomaly detection use casesHere are some diverse applications of anomaly detection using machine learning:Event detection in sensor networksManufacturing quality controlHealthcare monitoringSocial media monitoringFraud detectionNetwork intrusion detectionHealthcare monitoringInsurance claim analysisCybersecurity threat detectionIdentity theftTraffic monitoringNetwork intrusion detectionData breachesIntrusion detectionVideo surveillanceThe three settings for anomaly detection, as described by Dr. Thomas Dietterich and his team at Oregon State University in 2018:Supervised Anomaly Detection: In this setting, the anomaly detection model is trained on a labeled dataset, which means that each data point is explicitly marked as either normal or anomalous. The model learns the characteristics of normal data and uses this knowledge to detect anomalies in new, unseen data. Supervised anomaly detection is effective when you have a reliable labeled dataset for training, and it is suitable for scenarios where anomalies are relatively easy to define and identify.ML Algorithm for structured data:- Bayesian networks- k-nearest neighbors (KNN)- Decision treesClean Anomaly Detection: Clean anomaly detection refers to situations where the data is mostly clean and free from noise or errors, making it easier to detect anomalies. In this setting, the focus is on identifying significant deviations from the established normal patterns. Clean anomaly detection is commonly used in applications where the data is well-structured and follows predictable patterns, such as fraud detection in\\nfrom the established normal patterns. Clean anomaly detection is commonly used in applications where the data is well-structured and follows predictable patterns, such as fraud detection in financial transactions or quality control in manufacturing.Unsupervised Anomaly Detection: Unsupervised anomaly detection occurs when there are no labeled anomalies in the training data, and the model needs to identify anomalies without prior knowledge of what constitutes an anomaly. The model’s task is to find data points that deviate significantly from the majority of the data, making it suitable for cases where anomalies are rare or poorly understood. ML algorithm for unstructured data:- K-means- One-class support vector machineHere are some common approaches to anomaly detection:Press enter or click to view image in full sizeStatistical methods:Z-Score/Standard Score: This method measures how many standard deviations a data point is away from the mean. Points that fall far from the mean are considered anomalies.Percentiles: Identifying anomalies based on percentiles or quantiles, where values below or above a certain threshold are considered outliers.Machine learning algorithms:Isolation Forest: An ensemble learning method that builds a tree structure to isolate anomalies efficiently.One-Class SVM: A support vector machine (SVM) model trained to classify data points as normal or outliers.K-Nearest Neighbors (KNN): Assigns an anomaly score based on the distance to the K-nearest neighbors, with distant points being potential anomalies.Autoencoders: Neural networks designed to learn a compressed representation of data, where reconstruction error can be used to identify anomalies.Clustering methods:DBSCAN (Density-Based Spatial Clustering of Applications with Noise): Clusters data points based on their density, with points that do not belong to any cluster considered outliers.K-Means Clustering: Data points that do not belong to well-defined clusters may be considered anomalies.Time-series analysis:Moving Averages: Identifying anomalies based on deviations from the moving average or exponential moving average.Seasonal Decomposition: Decomposing a time series into its trend, seasonal, and residual components, with anomalies often detected in the residual component.Proximity-based approaches:Mahalanobis Distance: Measures the distance of data points from the center of the data distribution, considering correlations between features.Local Outlier Factor (LOF): Computes the local density deviation of a data point compared to its neighbors, identifying regions of different densities.Let’s dive a bit deeper into how DBSCAN works with a simple analogyDBSCAN (Density-Based Spatial Clustering of Applications with Noise) is a clever way to find unusual or outlier data points in a group of data. Imagine you have a bunch of points on a map, and you want to find the weird ones that don’t really fit into any group.Here’s how DBSCAN works:Step 1: Select a starting pointBegin by randomly selecting a data point from your dataset.Step 2: Define a radius (Epsilon) and minimum number of oints (Min_Samples)Specify two important values:Epsilon (a radius around the selected point).Min_Samples (the minimum number of data points that should be within this radius to form a cluster)Step 3: Check neighboring pointsExamine all data points within the defined radius (Epsilon) around the selected point.Step 4: Form a clusterIf there are at least as many data points within the Epsilon radius as specified by Min_Samples, consider the selected point and these nearby points as a cluster.Step 5: Expand the clusterNow, for each point within this newly formed cluster, repeat the process. Check for nearby points within the Epsilon radius.If additional points are found, add them to the cluster. This process continues iteratively, expanding the cluster until no more points can be added.Step 6: Identify outliers (noise)Any data points that are not included in any cluster after the\\ncluster. This process continues iteratively, expanding the cluster until no more points can be added.Step 6: Identify outliers (noise)Any data points that are not included in any cluster after the expansion process are labeled as outliers or noise. These points do not belong to any cluster.Imagine you have a field with a bunch of people scattered around, and you want to organize a game of tag. Some people are standing close together, and others are standing alone. DBSCAN helps you identify two things:Groups of Players: It starts by picking a person, any person, and puts an imaginary hula hoop around them (this is like setting a maximum distance). Now, it checks how many other people are inside that hula hoop. If there are enough (more than a certain number you decide in advance), it forms a group. This group is like a team of players playing tag.Lonely Players: After forming that group, it picks a person within that group, puts a hula hoop around them, and checks if there are more people inside. If yes, it adds them to the group. This process continues until there are no more people to add to that group.Now, here’s the cool part: Anyone who doesn’t end up in a group is the outlier or the “lonely player.” These are the people who don’t belong to any team, or in data terms, they are the outliers.To apply DBSCAN for outlier detection in Python using Scikit-Learn, we begin by importing the necessary libraries and modules, as follows:Step 1: Import necessary librariesThe code starts by importing the required Python libraries, including NumPy for numerical operations, Matplotlib for data visualization, and the DBSCAN class from scikit-learn for implementing the DBSCAN algorithm.import numpy as npimport matplotlib.pyplot as pltfrom sklearn.cluster import DBSCANfrom sklearn.datasets import make_blobsStep 2: Create a synthetic dataset# Create a synthetic dataset with normal and anomalous data pointsn_samples = 300X, y = make_blobs(n_samples=n_samples, centers=2, random_state=42, cluster_std=1.0)anomalies = np.array([[5, 5], [6, 6], [7, 7]])In this step, a synthetic dataset is generated to illustrate the concept. The dataset is created using the make_blobs function, producing two clusters of data points with some isolated anomalies.n_samples determines the total number of data points, and the centers parameter specifies the number of clusters (2, in this case).The anomalies variable is an array of manually created anomalous data points.Step 3: Combine normal and anomalous data# Combine the normal data and anomaliesX = np.vstack([X, anomalies])The normal data and anomalies are combined into a single dataset represented by the X array using np.vstack.Step 4: Visualize the dataset# Visualize the datasetplt.scatter(X[:, 0], X[:, 1], c=\\'b\\', marker=\\'o\\', s=25)plt.title(\"Synthetic Dataset\")plt.show()The code plots the dataset to provide a visual representation. It uses Matplotlib to create a scatter plot, where normal data points are marked in blue circles.The resulting plot visually shows two clusters and some isolated red crosses representing the anomalies.Step 5: Apply DBSCAN for anomaly detection# Apply DBSCAN for anomaly detection with increased epsilondbscan = DBSCAN(eps=1, min_samples=41)  # Increase epslabels = dbscan.fit_predict(X)# Anomalies are considered as points with label -1anomalies = X[labels == -1]DBSCAN is applied for anomaly detection using the DBSCAN class from scikit-learn. The parameters eps (epsilon) and min_samples control the algorithm\\'s behavior.The eps parameter sets the radius within which points are considered neighbors.The min_samples parameter defines the minimum number of points required to form a cluster.The code then fits the DBSCAN model to the dataset using fit_predict to obtain cluster labels for each data point.Step 6: Identify anomalies# Anomalies are considered as points with label -1anomalies = X[labels == -1]Anomalies are identified by finding data points labeled as -1. These points do not belong to\\n6: Identify anomalies# Anomalies are considered as points with label -1anomalies = X[labels == -1]Anomalies are identified by finding data points labeled as -1. These points do not belong to any cluster and are considered outliers or anomalies.Step 7: Visualize the anomalies# Visualize the anomaliesplt.scatter(X[:, 0], X[:, 1], c=\\'b\\', marker=\\'o\\', s=25)plt.scatter(anomalies[:, 0], anomalies[:, 1], c=\\'r\\', marker=\\'x\\', s=50, label=\\'Anomalies\\')plt.title(\"Anomaly Detection with DBSCAN (Anomalies Outside Clusters)\")plt.legend()plt.show()The code plots the anomalies found by DBSCAN in red crosses on top of the original data points.This visualization helps to highlight the anomalies detected by the algorithm.Step 8: Print the identified anomalies# Print the identified anomaliesprint(\"Identified Anomalies:\")print(anomalies)The code concludes by printing the coordinates of the identified anomalies, allowing you to see the specific data points classified as anomalies by the DBSCAN algorithm.By following these steps, you can effectively identify an anomaly with DBSCAN and visualize its results.ConclusionDBSCAN is a valuable tool for anomaly detection, offering a data-driven approach to uncovering outliers in complex datasets. By following the step-by-step guide and code provided in this blog post, you can integrate DBSCAN into your own data analysis projects, enhance your anomaly detection capabilities, and make more informed decisions based on the unique insights that outliers can provide.Follow Simform Engineering to keep yourself updated with the latest trends in the technology horizon. Follow us: Twitter | LinkedInReferencesAnomaly detection with practical exampleImagine you are working as a sysadmin in a fintech company. There can be an issue in the front-end that stops your…towardsdatascience.comUnsupervised learning for anomaly detection - CENTUM DigitalLa identificación de anomalías puede suponer una gran ventaja para tu empresa. Aquí te contamos cómo el aprendizaje no…centum.comHow to do Anomaly Detection using Machine Learning in Python?Anomaly Detection using Machine Learning in Python Example | ProjectProwww.projectpro.ioAlgorithm selection for Anomaly DetectionAnomalies can be defined as observations which deviate sufficiently from most observations in the data set to consider…medium.comUnsupervised LearningAnomaly DetectionMachine LearningDbscan Algorithm----1Published in Simform Engineering1.4K followers·Last published\\xa01 day agoOur Engineering blog gives an inside look at our technologies from the perspective of our engineers.Written by Hiraltalsaniya20 followers·28 followingResponses (1)See all responsesHelpStatusAboutCareersPressBlogPrivacyRulesTermsText to speech'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T00:54:02.473739Z",
     "start_time": "2025-10-05T00:54:02.466658Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from IPython.display import  Markdown\n",
    "Markdown(anamoly_doc_obj.page_content)"
   ],
   "id": "21fccbf05cd682d4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Anomaly Detection with Unsupervised Machine Learning | by Hiraltalsaniya | Simform Engineering | MediumSitemapOpen in appSign upSign inMedium LogoWriteSearchSign upSign inSimform Engineering·Our Engineering blog gives an inside look at our technologies from the perspective of our engineers.Anomaly Detection with Unsupervised Machine LearningHiraltalsaniya9 min read·Dec 22, 2023--1ListenShareDetecting Outliers and Unusual Data Patterns with Unsupervised LearningPress enter or click to view image in full sizeIn an era of big data, anomaly detection has become a crucial capability for unlocking hidden insights and ensuring data integrity. This blog dives into the world of unsupervised machine learning techniques to detect outliers efficiently without labeled data.We introduce key anomaly detection concepts, demonstrate anomaly detection methodologies and use cases, compare supervised and unsupervised models, and provide a step-by-step implementation guide using DBSCAN in Python.What is an anomaly?An anomaly is basically something that’s unusual, doesn’t fit the usual pattern, or stands out because it’s different in a specific category or situation. To explain it simply, let’s look at some clear examples:Think about a collection of smartphones, mostly from Samsung, and then there’s an iPhone. The iPhone is an anomaly because it’s a different brand.Imagine you have a bunch of pens, but one of them is a fancy fountain pen instead of a regular ballpoint pen. That fountain pen is an anomaly because it’s not like the others.What is anomaly detection?Anomaly detection is a technique used to identify data points that are significantly different or “outliers” when compared to the majority of the data in a dataset.Anomaly detection is about finding data points that are different from what is considered normal or expected, and it relies on historical data or established knowledge to determine what falls within the usual range. It plays a crucial role in ensuring the quality and security of data in various domains.Press enter or click to view image in full sizeExample of anomaly detection in server logs:Normal behavior:Website traffic follows a regular pattern.Requests per minute show a predictable trend, with slight increases during peak hours.Anomaly:Suddenly, there is an unusual, significant surge in traffic.This spike in requests per minute is an anomaly in the server logs.Anomaly detection use casesHere are some diverse applications of anomaly detection using machine learning:Event detection in sensor networksManufacturing quality controlHealthcare monitoringSocial media monitoringFraud detectionNetwork intrusion detectionHealthcare monitoringInsurance claim analysisCybersecurity threat detectionIdentity theftTraffic monitoringNetwork intrusion detectionData breachesIntrusion detectionVideo surveillanceThe three settings for anomaly detection, as described by Dr. Thomas Dietterich and his team at Oregon State University in 2018:Supervised Anomaly Detection: In this setting, the anomaly detection model is trained on a labeled dataset, which means that each data point is explicitly marked as either normal or anomalous. The model learns the characteristics of normal data and uses this knowledge to detect anomalies in new, unseen data. Supervised anomaly detection is effective when you have a reliable labeled dataset for training, and it is suitable for scenarios where anomalies are relatively easy to define and identify.ML Algorithm for structured data:- Bayesian networks- k-nearest neighbors (KNN)- Decision treesClean Anomaly Detection: Clean anomaly detection refers to situations where the data is mostly clean and free from noise or errors, making it easier to detect anomalies. In this setting, the focus is on identifying significant deviations from the established normal patterns. Clean anomaly detection is commonly used in applications where the data is well-structured and follows predictable patterns, such as fraud detection in\nfrom the established normal patterns. Clean anomaly detection is commonly used in applications where the data is well-structured and follows predictable patterns, such as fraud detection in financial transactions or quality control in manufacturing.Unsupervised Anomaly Detection: Unsupervised anomaly detection occurs when there are no labeled anomalies in the training data, and the model needs to identify anomalies without prior knowledge of what constitutes an anomaly. The model’s task is to find data points that deviate significantly from the majority of the data, making it suitable for cases where anomalies are rare or poorly understood. ML algorithm for unstructured data:- K-means- One-class support vector machineHere are some common approaches to anomaly detection:Press enter or click to view image in full sizeStatistical methods:Z-Score/Standard Score: This method measures how many standard deviations a data point is away from the mean. Points that fall far from the mean are considered anomalies.Percentiles: Identifying anomalies based on percentiles or quantiles, where values below or above a certain threshold are considered outliers.Machine learning algorithms:Isolation Forest: An ensemble learning method that builds a tree structure to isolate anomalies efficiently.One-Class SVM: A support vector machine (SVM) model trained to classify data points as normal or outliers.K-Nearest Neighbors (KNN): Assigns an anomaly score based on the distance to the K-nearest neighbors, with distant points being potential anomalies.Autoencoders: Neural networks designed to learn a compressed representation of data, where reconstruction error can be used to identify anomalies.Clustering methods:DBSCAN (Density-Based Spatial Clustering of Applications with Noise): Clusters data points based on their density, with points that do not belong to any cluster considered outliers.K-Means Clustering: Data points that do not belong to well-defined clusters may be considered anomalies.Time-series analysis:Moving Averages: Identifying anomalies based on deviations from the moving average or exponential moving average.Seasonal Decomposition: Decomposing a time series into its trend, seasonal, and residual components, with anomalies often detected in the residual component.Proximity-based approaches:Mahalanobis Distance: Measures the distance of data points from the center of the data distribution, considering correlations between features.Local Outlier Factor (LOF): Computes the local density deviation of a data point compared to its neighbors, identifying regions of different densities.Let’s dive a bit deeper into how DBSCAN works with a simple analogyDBSCAN (Density-Based Spatial Clustering of Applications with Noise) is a clever way to find unusual or outlier data points in a group of data. Imagine you have a bunch of points on a map, and you want to find the weird ones that don’t really fit into any group.Here’s how DBSCAN works:Step 1: Select a starting pointBegin by randomly selecting a data point from your dataset.Step 2: Define a radius (Epsilon) and minimum number of oints (Min_Samples)Specify two important values:Epsilon (a radius around the selected point).Min_Samples (the minimum number of data points that should be within this radius to form a cluster)Step 3: Check neighboring pointsExamine all data points within the defined radius (Epsilon) around the selected point.Step 4: Form a clusterIf there are at least as many data points within the Epsilon radius as specified by Min_Samples, consider the selected point and these nearby points as a cluster.Step 5: Expand the clusterNow, for each point within this newly formed cluster, repeat the process. Check for nearby points within the Epsilon radius.If additional points are found, add them to the cluster. This process continues iteratively, expanding the cluster until no more points can be added.Step 6: Identify outliers (noise)Any data points that are not included in any cluster after the\ncluster. This process continues iteratively, expanding the cluster until no more points can be added.Step 6: Identify outliers (noise)Any data points that are not included in any cluster after the expansion process are labeled as outliers or noise. These points do not belong to any cluster.Imagine you have a field with a bunch of people scattered around, and you want to organize a game of tag. Some people are standing close together, and others are standing alone. DBSCAN helps you identify two things:Groups of Players: It starts by picking a person, any person, and puts an imaginary hula hoop around them (this is like setting a maximum distance). Now, it checks how many other people are inside that hula hoop. If there are enough (more than a certain number you decide in advance), it forms a group. This group is like a team of players playing tag.Lonely Players: After forming that group, it picks a person within that group, puts a hula hoop around them, and checks if there are more people inside. If yes, it adds them to the group. This process continues until there are no more people to add to that group.Now, here’s the cool part: Anyone who doesn’t end up in a group is the outlier or the “lonely player.” These are the people who don’t belong to any team, or in data terms, they are the outliers.To apply DBSCAN for outlier detection in Python using Scikit-Learn, we begin by importing the necessary libraries and modules, as follows:Step 1: Import necessary librariesThe code starts by importing the required Python libraries, including NumPy for numerical operations, Matplotlib for data visualization, and the DBSCAN class from scikit-learn for implementing the DBSCAN algorithm.import numpy as npimport matplotlib.pyplot as pltfrom sklearn.cluster import DBSCANfrom sklearn.datasets import make_blobsStep 2: Create a synthetic dataset# Create a synthetic dataset with normal and anomalous data pointsn_samples = 300X, y = make_blobs(n_samples=n_samples, centers=2, random_state=42, cluster_std=1.0)anomalies = np.array([[5, 5], [6, 6], [7, 7]])In this step, a synthetic dataset is generated to illustrate the concept. The dataset is created using the make_blobs function, producing two clusters of data points with some isolated anomalies.n_samples determines the total number of data points, and the centers parameter specifies the number of clusters (2, in this case).The anomalies variable is an array of manually created anomalous data points.Step 3: Combine normal and anomalous data# Combine the normal data and anomaliesX = np.vstack([X, anomalies])The normal data and anomalies are combined into a single dataset represented by the X array using np.vstack.Step 4: Visualize the dataset# Visualize the datasetplt.scatter(X[:, 0], X[:, 1], c='b', marker='o', s=25)plt.title(\"Synthetic Dataset\")plt.show()The code plots the dataset to provide a visual representation. It uses Matplotlib to create a scatter plot, where normal data points are marked in blue circles.The resulting plot visually shows two clusters and some isolated red crosses representing the anomalies.Step 5: Apply DBSCAN for anomaly detection# Apply DBSCAN for anomaly detection with increased epsilondbscan = DBSCAN(eps=1, min_samples=41)  # Increase epslabels = dbscan.fit_predict(X)# Anomalies are considered as points with label -1anomalies = X[labels == -1]DBSCAN is applied for anomaly detection using the DBSCAN class from scikit-learn. The parameters eps (epsilon) and min_samples control the algorithm's behavior.The eps parameter sets the radius within which points are considered neighbors.The min_samples parameter defines the minimum number of points required to form a cluster.The code then fits the DBSCAN model to the dataset using fit_predict to obtain cluster labels for each data point.Step 6: Identify anomalies# Anomalies are considered as points with label -1anomalies = X[labels == -1]Anomalies are identified by finding data points labeled as -1. These points do not belong to\n6: Identify anomalies# Anomalies are considered as points with label -1anomalies = X[labels == -1]Anomalies are identified by finding data points labeled as -1. These points do not belong to any cluster and are considered outliers or anomalies.Step 7: Visualize the anomalies# Visualize the anomaliesplt.scatter(X[:, 0], X[:, 1], c='b', marker='o', s=25)plt.scatter(anomalies[:, 0], anomalies[:, 1], c='r', marker='x', s=50, label='Anomalies')plt.title(\"Anomaly Detection with DBSCAN (Anomalies Outside Clusters)\")plt.legend()plt.show()The code plots the anomalies found by DBSCAN in red crosses on top of the original data points.This visualization helps to highlight the anomalies detected by the algorithm.Step 8: Print the identified anomalies# Print the identified anomaliesprint(\"Identified Anomalies:\")print(anomalies)The code concludes by printing the coordinates of the identified anomalies, allowing you to see the specific data points classified as anomalies by the DBSCAN algorithm.By following these steps, you can effectively identify an anomaly with DBSCAN and visualize its results.ConclusionDBSCAN is a valuable tool for anomaly detection, offering a data-driven approach to uncovering outliers in complex datasets. By following the step-by-step guide and code provided in this blog post, you can integrate DBSCAN into your own data analysis projects, enhance your anomaly detection capabilities, and make more informed decisions based on the unique insights that outliers can provide.Follow Simform Engineering to keep yourself updated with the latest trends in the technology horizon. Follow us: Twitter | LinkedInReferencesAnomaly detection with practical exampleImagine you are working as a sysadmin in a fintech company. There can be an issue in the front-end that stops your…towardsdatascience.comUnsupervised learning for anomaly detection - CENTUM DigitalLa identificación de anomalías puede suponer una gran ventaja para tu empresa. Aquí te contamos cómo el aprendizaje no…centum.comHow to do Anomaly Detection using Machine Learning in Python?Anomaly Detection using Machine Learning in Python Example | ProjectProwww.projectpro.ioAlgorithm selection for Anomaly DetectionAnomalies can be defined as observations which deviate sufficiently from most observations in the data set to consider…medium.comUnsupervised LearningAnomaly DetectionMachine LearningDbscan Algorithm----1Published in Simform Engineering1.4K followers·Last published 1 day agoOur Engineering blog gives an inside look at our technologies from the perspective of our engineers.Written by Hiraltalsaniya20 followers·28 followingResponses (1)See all responsesHelpStatusAboutCareersPressBlogPrivacyRulesTermsText to speech"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T00:54:05.104998Z",
     "start_time": "2025-10-05T00:54:04.190472Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "embeddings = OllamaEmbeddings(model=MODEL)"
   ],
   "id": "22ea257846e1f5d7",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T00:55:52.889006Z",
     "start_time": "2025-10-05T00:54:08.434408Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "vectordb = Chroma.from_documents(langchain_docs, embedding=embeddings)\n",
    "vectordb"
   ],
   "id": "ff955536108dbddd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_chroma.vectorstores.Chroma at 0x21bf14e82c0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T00:55:52.895479Z",
     "start_time": "2025-10-05T00:55:52.889612Z"
    }
   },
   "cell_type": "code",
   "source": [
    "retriever = vectordb.as_retriever()\n",
    "retriever   "
   ],
   "id": "e3f68ada8dc04c01",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['Chroma', 'OllamaEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x0000021BF14E82C0>, search_kwargs={})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T00:55:56.322250Z",
     "start_time": "2025-10-05T00:55:55.668566Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "local_llm=ChatOllama(model=MODEL,temperature=0)\n",
    "type(local_llm)"
   ],
   "id": "8eb5e5569a3703c5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_ollama.chat_models.ChatOllama"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T00:55:57.360503Z",
     "start_time": "2025-10-05T00:55:57.351358Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "prompt"
   ],
   "id": "4b76776892ed8c95",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, say that you don't know. Use three sentences maximum and keep the answer concise.\\n\\n{context}\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T00:55:58.852286Z",
     "start_time": "2025-10-05T00:55:58.841768Z"
    }
   },
   "cell_type": "code",
   "source": [
    "question_ans_chain = create_stuff_documents_chain(local_llm,prompt)\n",
    "\n",
    "question_ans_chain"
   ],
   "id": "3ce75c53631e6c6d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableLambda(format_docs)\n",
       "}), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "| ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, say that you don't know. Use three sentences maximum and keep the answer concise.\\n\\n{context}\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "| ChatOllama(model='llama3.2', temperature=0.0)\n",
       "| StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T00:56:00.092458Z",
     "start_time": "2025-10-05T00:56:00.089509Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# query =\"Do you know anything about anomaly?\"\n",
    "query =\"How can you use anomaly deduction for monitoring an application latency?\"\n",
    "\n",
    "rag_chain = create_retrieval_chain(retriever,question_ans_chain)\n"
   ],
   "id": "25b57994824f61d5",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T00:58:27.098580Z",
     "start_time": "2025-10-05T00:56:02.913593Z"
    }
   },
   "cell_type": "code",
   "source": [
    "results = rag_chain.invoke({\"input\" : query})\n",
    "results"
   ],
   "id": "7bedc2ea600395cf",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'How can you use anomaly deduction for monitoring an application latency?',\n",
       " 'context': [Document(id='d22d3c7a-9162-4df7-8473-d71aa26cbb30', metadata={'num_chunks': 1}, page_content=\"Vercel Security Checkpoint                  We're verifying your browser  Website owner? Click here to fix       Vercel Security Checkpoint | iad1::1759625628-DDjT8AGoDNVohG6hOhUWnrzIaph0TOCE                     Enable JavaScript to continue    Vercel Security Checkpoint | iad1::1759625628-DDjT8AGoDNVohG6hOhUWnrzIaph0TOCE\"),\n",
       "  Document(id='088a2567-9a01-4a19-aa26-d43c82723aae', metadata={'num_chunks': 4}, page_content='Anomaly Detection with Unsupervised Machine Learning | by Hiraltalsaniya | Simform Engineering | MediumSitemapOpen in appSign upSign inMedium LogoWriteSearchSign upSign inSimform Engineering·Our Engineering blog gives an inside look at our technologies from the perspective of our engineers.Anomaly Detection with Unsupervised Machine LearningHiraltalsaniya9 min read·Dec 22, 2023--1ListenShareDetecting Outliers and Unusual Data Patterns with Unsupervised LearningPress enter or click to view image in full sizeIn an era of big data, anomaly detection has become a crucial capability for unlocking hidden insights and ensuring data integrity. This blog dives into the world of unsupervised machine learning techniques to detect outliers efficiently without labeled data.We introduce key anomaly detection concepts, demonstrate anomaly detection methodologies and use cases, compare supervised and unsupervised models, and provide a step-by-step implementation guide using DBSCAN in Python.What is an anomaly?An anomaly is basically something that’s unusual, doesn’t fit the usual pattern, or stands out because it’s different in a specific category or situation. To explain it simply, let’s look at some clear examples:Think about a collection of smartphones, mostly from Samsung, and then there’s an iPhone. The iPhone is an anomaly because it’s a different brand.Imagine you have a bunch of pens, but one of them is a fancy fountain pen instead of a regular ballpoint pen. That fountain pen is an anomaly because it’s not like the others.What is anomaly detection?Anomaly detection is a technique used to identify data points that are significantly different or “outliers” when compared to the majority of the data in a dataset.Anomaly detection is about finding data points that are different from what is considered normal or expected, and it relies on historical data or established knowledge to determine what falls within the usual range. It plays a crucial role in ensuring the quality and security of data in various domains.Press enter or click to view image in full sizeExample of anomaly detection in server logs:Normal behavior:Website traffic follows a regular pattern.Requests per minute show a predictable trend, with slight increases during peak hours.Anomaly:Suddenly, there is an unusual, significant surge in traffic.This spike in requests per minute is an anomaly in the server logs.Anomaly detection use casesHere are some diverse applications of anomaly detection using machine learning:Event detection in sensor networksManufacturing quality controlHealthcare monitoringSocial media monitoringFraud detectionNetwork intrusion detectionHealthcare monitoringInsurance claim analysisCybersecurity threat detectionIdentity theftTraffic monitoringNetwork intrusion detectionData breachesIntrusion detectionVideo surveillanceThe three settings for anomaly detection, as described by Dr. Thomas Dietterich and his team at Oregon State University in 2018:Supervised Anomaly Detection: In this setting, the anomaly detection model is trained on a labeled dataset, which means that each data point is explicitly marked as either normal or anomalous. The model learns the characteristics of normal data and uses this knowledge to detect anomalies in new, unseen data. Supervised anomaly detection is effective when you have a reliable labeled dataset for training, and it is suitable for scenarios where anomalies are relatively easy to define and identify.ML Algorithm for structured data:- Bayesian networks- k-nearest neighbors (KNN)- Decision treesClean Anomaly Detection: Clean anomaly detection refers to situations where the data is mostly clean and free from noise or errors, making it easier to detect anomalies. In this setting, the focus is on identifying significant deviations from the established normal patterns. Clean anomaly detection is commonly used in applications where the data is well-structured and follows predictable patterns, such as fraud detection in\\nfrom the established normal patterns. Clean anomaly detection is commonly used in applications where the data is well-structured and follows predictable patterns, such as fraud detection in financial transactions or quality control in manufacturing.Unsupervised Anomaly Detection: Unsupervised anomaly detection occurs when there are no labeled anomalies in the training data, and the model needs to identify anomalies without prior knowledge of what constitutes an anomaly. The model’s task is to find data points that deviate significantly from the majority of the data, making it suitable for cases where anomalies are rare or poorly understood. ML algorithm for unstructured data:- K-means- One-class support vector machineHere are some common approaches to anomaly detection:Press enter or click to view image in full sizeStatistical methods:Z-Score/Standard Score: This method measures how many standard deviations a data point is away from the mean. Points that fall far from the mean are considered anomalies.Percentiles: Identifying anomalies based on percentiles or quantiles, where values below or above a certain threshold are considered outliers.Machine learning algorithms:Isolation Forest: An ensemble learning method that builds a tree structure to isolate anomalies efficiently.One-Class SVM: A support vector machine (SVM) model trained to classify data points as normal or outliers.K-Nearest Neighbors (KNN): Assigns an anomaly score based on the distance to the K-nearest neighbors, with distant points being potential anomalies.Autoencoders: Neural networks designed to learn a compressed representation of data, where reconstruction error can be used to identify anomalies.Clustering methods:DBSCAN (Density-Based Spatial Clustering of Applications with Noise): Clusters data points based on their density, with points that do not belong to any cluster considered outliers.K-Means Clustering: Data points that do not belong to well-defined clusters may be considered anomalies.Time-series analysis:Moving Averages: Identifying anomalies based on deviations from the moving average or exponential moving average.Seasonal Decomposition: Decomposing a time series into its trend, seasonal, and residual components, with anomalies often detected in the residual component.Proximity-based approaches:Mahalanobis Distance: Measures the distance of data points from the center of the data distribution, considering correlations between features.Local Outlier Factor (LOF): Computes the local density deviation of a data point compared to its neighbors, identifying regions of different densities.Let’s dive a bit deeper into how DBSCAN works with a simple analogyDBSCAN (Density-Based Spatial Clustering of Applications with Noise) is a clever way to find unusual or outlier data points in a group of data. Imagine you have a bunch of points on a map, and you want to find the weird ones that don’t really fit into any group.Here’s how DBSCAN works:Step 1: Select a starting pointBegin by randomly selecting a data point from your dataset.Step 2: Define a radius (Epsilon) and minimum number of oints (Min_Samples)Specify two important values:Epsilon (a radius around the selected point).Min_Samples (the minimum number of data points that should be within this radius to form a cluster)Step 3: Check neighboring pointsExamine all data points within the defined radius (Epsilon) around the selected point.Step 4: Form a clusterIf there are at least as many data points within the Epsilon radius as specified by Min_Samples, consider the selected point and these nearby points as a cluster.Step 5: Expand the clusterNow, for each point within this newly formed cluster, repeat the process. Check for nearby points within the Epsilon radius.If additional points are found, add them to the cluster. This process continues iteratively, expanding the cluster until no more points can be added.Step 6: Identify outliers (noise)Any data points that are not included in any cluster after the\\ncluster. This process continues iteratively, expanding the cluster until no more points can be added.Step 6: Identify outliers (noise)Any data points that are not included in any cluster after the expansion process are labeled as outliers or noise. These points do not belong to any cluster.Imagine you have a field with a bunch of people scattered around, and you want to organize a game of tag. Some people are standing close together, and others are standing alone. DBSCAN helps you identify two things:Groups of Players: It starts by picking a person, any person, and puts an imaginary hula hoop around them (this is like setting a maximum distance). Now, it checks how many other people are inside that hula hoop. If there are enough (more than a certain number you decide in advance), it forms a group. This group is like a team of players playing tag.Lonely Players: After forming that group, it picks a person within that group, puts a hula hoop around them, and checks if there are more people inside. If yes, it adds them to the group. This process continues until there are no more people to add to that group.Now, here’s the cool part: Anyone who doesn’t end up in a group is the outlier or the “lonely player.” These are the people who don’t belong to any team, or in data terms, they are the outliers.To apply DBSCAN for outlier detection in Python using Scikit-Learn, we begin by importing the necessary libraries and modules, as follows:Step 1: Import necessary librariesThe code starts by importing the required Python libraries, including NumPy for numerical operations, Matplotlib for data visualization, and the DBSCAN class from scikit-learn for implementing the DBSCAN algorithm.import numpy as npimport matplotlib.pyplot as pltfrom sklearn.cluster import DBSCANfrom sklearn.datasets import make_blobsStep 2: Create a synthetic dataset# Create a synthetic dataset with normal and anomalous data pointsn_samples = 300X, y = make_blobs(n_samples=n_samples, centers=2, random_state=42, cluster_std=1.0)anomalies = np.array([[5, 5], [6, 6], [7, 7]])In this step, a synthetic dataset is generated to illustrate the concept. The dataset is created using the make_blobs function, producing two clusters of data points with some isolated anomalies.n_samples determines the total number of data points, and the centers parameter specifies the number of clusters (2, in this case).The anomalies variable is an array of manually created anomalous data points.Step 3: Combine normal and anomalous data# Combine the normal data and anomaliesX = np.vstack([X, anomalies])The normal data and anomalies are combined into a single dataset represented by the X array using np.vstack.Step 4: Visualize the dataset# Visualize the datasetplt.scatter(X[:, 0], X[:, 1], c=\\'b\\', marker=\\'o\\', s=25)plt.title(\"Synthetic Dataset\")plt.show()The code plots the dataset to provide a visual representation. It uses Matplotlib to create a scatter plot, where normal data points are marked in blue circles.The resulting plot visually shows two clusters and some isolated red crosses representing the anomalies.Step 5: Apply DBSCAN for anomaly detection# Apply DBSCAN for anomaly detection with increased epsilondbscan = DBSCAN(eps=1, min_samples=41)  # Increase epslabels = dbscan.fit_predict(X)# Anomalies are considered as points with label -1anomalies = X[labels == -1]DBSCAN is applied for anomaly detection using the DBSCAN class from scikit-learn. The parameters eps (epsilon) and min_samples control the algorithm\\'s behavior.The eps parameter sets the radius within which points are considered neighbors.The min_samples parameter defines the minimum number of points required to form a cluster.The code then fits the DBSCAN model to the dataset using fit_predict to obtain cluster labels for each data point.Step 6: Identify anomalies# Anomalies are considered as points with label -1anomalies = X[labels == -1]Anomalies are identified by finding data points labeled as -1. These points do not belong to\\n6: Identify anomalies# Anomalies are considered as points with label -1anomalies = X[labels == -1]Anomalies are identified by finding data points labeled as -1. These points do not belong to any cluster and are considered outliers or anomalies.Step 7: Visualize the anomalies# Visualize the anomaliesplt.scatter(X[:, 0], X[:, 1], c=\\'b\\', marker=\\'o\\', s=25)plt.scatter(anomalies[:, 0], anomalies[:, 1], c=\\'r\\', marker=\\'x\\', s=50, label=\\'Anomalies\\')plt.title(\"Anomaly Detection with DBSCAN (Anomalies Outside Clusters)\")plt.legend()plt.show()The code plots the anomalies found by DBSCAN in red crosses on top of the original data points.This visualization helps to highlight the anomalies detected by the algorithm.Step 8: Print the identified anomalies# Print the identified anomaliesprint(\"Identified Anomalies:\")print(anomalies)The code concludes by printing the coordinates of the identified anomalies, allowing you to see the specific data points classified as anomalies by the DBSCAN algorithm.By following these steps, you can effectively identify an anomaly with DBSCAN and visualize its results.ConclusionDBSCAN is a valuable tool for anomaly detection, offering a data-driven approach to uncovering outliers in complex datasets. By following the step-by-step guide and code provided in this blog post, you can integrate DBSCAN into your own data analysis projects, enhance your anomaly detection capabilities, and make more informed decisions based on the unique insights that outliers can provide.Follow Simform Engineering to keep yourself updated with the latest trends in the technology horizon. Follow us: Twitter | LinkedInReferencesAnomaly detection with practical exampleImagine you are working as a sysadmin in a fintech company. There can be an issue in the front-end that stops your…towardsdatascience.comUnsupervised learning for anomaly detection - CENTUM DigitalLa identificación de anomalías puede suponer una gran ventaja para tu empresa. Aquí te contamos cómo el aprendizaje no…centum.comHow to do Anomaly Detection using Machine Learning in Python?Anomaly Detection using Machine Learning in Python Example | ProjectProwww.projectpro.ioAlgorithm selection for Anomaly DetectionAnomalies can be defined as observations which deviate sufficiently from most observations in the data set to consider…medium.comUnsupervised LearningAnomaly DetectionMachine LearningDbscan Algorithm----1Published in Simform Engineering1.4K followers·Last published\\xa01 day agoOur Engineering blog gives an inside look at our technologies from the perspective of our engineers.Written by Hiraltalsaniya20 followers·28 followingResponses (1)See all responsesHelpStatusAboutCareersPressBlogPrivacyRulesTermsText to speech')],\n",
       " 'answer': \"Anomaly detection can be used to monitor application latency by identifying unusual patterns or spikes in response times. Here's a step-by-step approach:\\n\\n1. **Collect latency data**: Gather latency metrics from your application, such as average response time, 95th percentile response time, and number of requests with high latency.\\n2. **Preprocessing**: Clean and preprocess the data to remove any noise or outliers. This may involve handling missing values, transforming data into a suitable format for analysis, and normalizing the data.\\n3. **Choose an algorithm**: Select an anomaly detection algorithm that suits your needs, such as One-Class SVM, Local Outlier Factor (LOF), or Isolation Forest.\\n4. **Train the model**: Train the chosen algorithm on historical latency data to learn the normal patterns and behavior of your application.\\n5. **Monitor live data**: Feed live latency data into the trained model to detect anomalies in real-time.\\n6. **Threshold setting**: Set a threshold for what constitutes an anomaly, based on the distribution of latency data and the chosen algorithm's sensitivity.\\n7. **Alerting and notification**: Configure alerts and notifications to be triggered when anomalies are detected, so that you can investigate and take corrective action.\\n\\nSome popular techniques for anomaly detection in application latency include:\\n\\n* **Time-series analysis**: Analyze latency data over time to identify patterns and trends.\\n* **Machine learning**: Use machine learning algorithms to detect anomalies based on historical data.\\n* **Statistical methods**: Apply statistical methods, such as Z-score or standard deviation, to identify outliers.\\n\\nExample of how you can use anomaly detection in Python using Scikit-Learn:\\n\\n```python\\nimport numpy as np\\nfrom sklearn.ensemble import IsolationForest\\nfrom sklearn.preprocessing import StandardScaler\\n\\n# Load latency data\\nlatency_data = pd.read_csv('latency_data.csv')\\n\\n# Preprocess data\\nscaler = StandardScaler()\\nlatency_data[['avg_response_time', '95th_percentile_response_time']] = scaler.fit_transform(latency_data[['avg_response_time', '95th_percentile_response_time']])\\n\\n# Train Isolation Forest model\\nmodel = IsolationForest(contamination=0.01)\\nmodel.fit(latency_data[['avg_response_time', '95th_percentile_response_time']])\\n\\n# Monitor live data\\nnew_latency_data = pd.DataFrame({'avg_response_time': [10, 20, 30], '95th_percentile_response_time': [15, 25, 35]})\\nnew_latency_data[['avg_response_time', '95th_percentile_response_time']] = scaler.transform(new_latency_data[['avg_response_time', '95th_percentile_response_time']])\\n\\n# Detect anomalies\\nanomalies = model.predict(new_latency_data[['avg_response_time', '95th_percentile_response_time']])\\n```\\n\\nIn this example, we use the Isolation Forest algorithm to detect anomalies in latency data. The `contamination` parameter is set to 0.01, which means that 1% of the data points are expected to be anomalies. The model is trained on historical data and then used to predict new latency data. Anomalies are detected based on the predicted values.\"}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T00:58:32.323099Z",
     "start_time": "2025-10-05T00:58:32.317526Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "final_answer = results[\"answer\"]\n",
    "Markdown(final_answer)"
   ],
   "id": "2b291ec640d13995",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Anomaly detection can be used to monitor application latency by identifying unusual patterns or spikes in response times. Here's a step-by-step approach:\n\n1. **Collect latency data**: Gather latency metrics from your application, such as average response time, 95th percentile response time, and number of requests with high latency.\n2. **Preprocessing**: Clean and preprocess the data to remove any noise or outliers. This may involve handling missing values, transforming data into a suitable format for analysis, and normalizing the data.\n3. **Choose an algorithm**: Select an anomaly detection algorithm that suits your needs, such as One-Class SVM, Local Outlier Factor (LOF), or Isolation Forest.\n4. **Train the model**: Train the chosen algorithm on historical latency data to learn the normal patterns and behavior of your application.\n5. **Monitor live data**: Feed live latency data into the trained model to detect anomalies in real-time.\n6. **Threshold setting**: Set a threshold for what constitutes an anomaly, based on the distribution of latency data and the chosen algorithm's sensitivity.\n7. **Alerting and notification**: Configure alerts and notifications to be triggered when anomalies are detected, so that you can investigate and take corrective action.\n\nSome popular techniques for anomaly detection in application latency include:\n\n* **Time-series analysis**: Analyze latency data over time to identify patterns and trends.\n* **Machine learning**: Use machine learning algorithms to detect anomalies based on historical data.\n* **Statistical methods**: Apply statistical methods, such as Z-score or standard deviation, to identify outliers.\n\nExample of how you can use anomaly detection in Python using Scikit-Learn:\n\n```python\nimport numpy as np\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.preprocessing import StandardScaler\n\n# Load latency data\nlatency_data = pd.read_csv('latency_data.csv')\n\n# Preprocess data\nscaler = StandardScaler()\nlatency_data[['avg_response_time', '95th_percentile_response_time']] = scaler.fit_transform(latency_data[['avg_response_time', '95th_percentile_response_time']])\n\n# Train Isolation Forest model\nmodel = IsolationForest(contamination=0.01)\nmodel.fit(latency_data[['avg_response_time', '95th_percentile_response_time']])\n\n# Monitor live data\nnew_latency_data = pd.DataFrame({'avg_response_time': [10, 20, 30], '95th_percentile_response_time': [15, 25, 35]})\nnew_latency_data[['avg_response_time', '95th_percentile_response_time']] = scaler.transform(new_latency_data[['avg_response_time', '95th_percentile_response_time']])\n\n# Detect anomalies\nanomalies = model.predict(new_latency_data[['avg_response_time', '95th_percentile_response_time']])\n```\n\nIn this example, we use the Isolation Forest algorithm to detect anomalies in latency data. The `contamination` parameter is set to 0.01, which means that 1% of the data points are expected to be anomalies. The model is trained on historical data and then used to predict new latency data. Anomalies are detected based on the predicted values."
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T00:58:52.035423Z",
     "start_time": "2025-10-05T00:58:52.021613Z"
    }
   },
   "cell_type": "code",
   "source": [
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    ('system', system_prompt),\n",
    "    ('human', '{input}')\n",
    "])\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "rag_chain_from_docs = (\n",
    "        {\n",
    "            'input': lambda x: x['input'],\n",
    "            'context': lambda x: format_docs(x['context']),\n",
    "        }\n",
    "        | prompt\n",
    "        | local_llm\n",
    "        | StrOutputParser()\n",
    ")"
   ],
   "id": "87c32a7f3db68e71",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T00:58:53.111397Z",
     "start_time": "2025-10-05T00:58:53.106052Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# passing the input query to the retriever\n",
    "retrieve_docs = (lambda x: x['input']) | retriever"
   ],
   "id": "134f59d186fcdb4b",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T00:58:54.116239Z",
     "start_time": "2025-10-05T00:58:54.110178Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chain = RunnablePassthrough.assign(context=retrieve_docs).assign(\n",
    "    answer=rag_chain_from_docs\n",
    ")\n",
    "chain"
   ],
   "id": "98b7bd610a4bc43a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableAssign(mapper={\n",
       "  context: RunnableLambda(lambda x: x['input'])\n",
       "           | VectorStoreRetriever(tags=['Chroma', 'OllamaEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x0000021BF14E82C0>, search_kwargs={})\n",
       "})\n",
       "| RunnableAssign(mapper={\n",
       "    answer: {\n",
       "              input: RunnableLambda(...),\n",
       "              context: RunnableLambda(...)\n",
       "            }\n",
       "            | ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, say that you don't know. Use three sentences maximum and keep the answer concise.\\n\\n{context}\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "            | ChatOllama(model='llama3.2', temperature=0.0)\n",
       "            | StrOutputParser()\n",
       "  })"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-10-05T00:58:55.421729Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query = \"Tell me if anomaly deduction falls under machine learning?\"\n",
    "chain.invoke({'input': query})"
   ],
   "id": "8c935cd794cab33c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "4d8658ece82a746c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "9cd8250ba07f6557",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "fe1199e502c6bd3e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "e124a11c2e84c02d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "4d0f280b55e87964",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "9345ff0bb4e762c3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "3e18c1f084c04c3d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "533b09c88065adb8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "3fcd3c318df7b15f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "1952a79611a4b733",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "df0a1ae8b8ece935",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "1afc6bc81b39fab",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "83f86cada6c78c9e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "65f40e096fabfadb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "d52f3ed200274e3a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "63292151f163d42b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "a4d93fbaf3124cde",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "116851ac0396f09f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "e440f73f2be9a7d8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "af15f35c4191fa3d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "c3c7fec9e5eae34e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "132e635052e32f03",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "fbedea44586ccb7c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "ae8ba48539b2a91f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "1505055547fce441",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
